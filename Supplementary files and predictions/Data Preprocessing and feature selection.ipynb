{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.width = 1200\n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PP1</th>\n",
       "      <th>PP2</th>\n",
       "      <th>PP3</th>\n",
       "      <th>KF1</th>\n",
       "      <th>KF2</th>\n",
       "      <th>KF3</th>\n",
       "      <th>KF4</th>\n",
       "      <th>KF5</th>\n",
       "      <th>KF6</th>\n",
       "      <th>KF7</th>\n",
       "      <th>KF8</th>\n",
       "      <th>KF9</th>\n",
       "      <th>KF10</th>\n",
       "      <th>Z1</th>\n",
       "      <th>Z2</th>\n",
       "      <th>Z3</th>\n",
       "      <th>Z4</th>\n",
       "      <th>Z5</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>VHSE1</th>\n",
       "      <th>VHSE2</th>\n",
       "      <th>VHSE3</th>\n",
       "      <th>VHSE4</th>\n",
       "      <th>VHSE5</th>\n",
       "      <th>VHSE6</th>\n",
       "      <th>VHSE7</th>\n",
       "      <th>VHSE8</th>\n",
       "      <th>ProtFP1</th>\n",
       "      <th>ProtFP2</th>\n",
       "      <th>ProtFP3</th>\n",
       "      <th>ProtFP4</th>\n",
       "      <th>ProtFP5</th>\n",
       "      <th>ProtFP6</th>\n",
       "      <th>ProtFP7</th>\n",
       "      <th>ProtFP8</th>\n",
       "      <th>ST1</th>\n",
       "      <th>ST2</th>\n",
       "      <th>ST3</th>\n",
       "      <th>ST4</th>\n",
       "      <th>ST5</th>\n",
       "      <th>ST6</th>\n",
       "      <th>ST7</th>\n",
       "      <th>ST8</th>\n",
       "      <th>BLOSUM1</th>\n",
       "      <th>BLOSUM2</th>\n",
       "      <th>BLOSUM3</th>\n",
       "      <th>BLOSUM4</th>\n",
       "      <th>BLOSUM5</th>\n",
       "      <th>BLOSUM6</th>\n",
       "      <th>BLOSUM7</th>\n",
       "      <th>BLOSUM8</th>\n",
       "      <th>BLOSUM9</th>\n",
       "      <th>BLOSUM10</th>\n",
       "      <th>MSWHIM1</th>\n",
       "      <th>MSWHIM2</th>\n",
       "      <th>MSWHIM3</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>Epitope</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LDRLFNKKKELGQDK</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.220667</td>\n",
       "      <td>-0.172667</td>\n",
       "      <td>0.055333</td>\n",
       "      <td>-0.175333</td>\n",
       "      <td>0.232667</td>\n",
       "      <td>-0.378667</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>-0.762000</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>0.285333</td>\n",
       "      <td>-0.877333</td>\n",
       "      <td>-0.329333</td>\n",
       "      <td>0.407333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.271067</td>\n",
       "      <td>0.096267</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>-0.059733</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>-3.556000</td>\n",
       "      <td>1.176000</td>\n",
       "      <td>-0.360667</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>-0.412000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.169333</td>\n",
       "      <td>0.358667</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>0.682667</td>\n",
       "      <td>-0.141333</td>\n",
       "      <td>-2.104000</td>\n",
       "      <td>1.502667</td>\n",
       "      <td>-0.427333</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>-0.546667</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.165333</td>\n",
       "      <td>-0.693933</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>-0.040067</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.075400</td>\n",
       "      <td>0.401733</td>\n",
       "      <td>0.146333</td>\n",
       "      <td>0.395867</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>-0.415333</td>\n",
       "      <td>-0.193333</td>\n",
       "      <td>0.127333</td>\n",
       "      <td>0.252667</td>\n",
       "      <td>-0.113333</td>\n",
       "      <td>0.211333</td>\n",
       "      <td>-0.048667</td>\n",
       "      <td>-0.317333</td>\n",
       "      <td>-0.208667</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>-0.072667</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LKLDRLFNKKKELGQ</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.094000</td>\n",
       "      <td>-0.111333</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>-0.283333</td>\n",
       "      <td>0.247333</td>\n",
       "      <td>-0.289333</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.108667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>-1.105333</td>\n",
       "      <td>-0.213333</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375867</td>\n",
       "      <td>0.182067</td>\n",
       "      <td>0.600600</td>\n",
       "      <td>-0.006733</td>\n",
       "      <td>0.157733</td>\n",
       "      <td>-3.538000</td>\n",
       "      <td>1.144667</td>\n",
       "      <td>-0.486000</td>\n",
       "      <td>0.329333</td>\n",
       "      <td>0.315333</td>\n",
       "      <td>-0.244667</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.220667</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.227333</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>-1.279333</td>\n",
       "      <td>1.351333</td>\n",
       "      <td>-0.338667</td>\n",
       "      <td>0.510667</td>\n",
       "      <td>-0.692000</td>\n",
       "      <td>0.769333</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>-0.688533</td>\n",
       "      <td>-0.004800</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>-0.078133</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>0.319333</td>\n",
       "      <td>-0.098000</td>\n",
       "      <td>-0.495333</td>\n",
       "      <td>-0.237333</td>\n",
       "      <td>0.195333</td>\n",
       "      <td>0.274667</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>-0.068000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.265333</td>\n",
       "      <td>0.256667</td>\n",
       "      <td>-0.019333</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NKYKLKLDRLFNKKK</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>-0.060667</td>\n",
       "      <td>0.552667</td>\n",
       "      <td>-0.140667</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>-1.067333</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.127333</td>\n",
       "      <td>0.221333</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.832667</td>\n",
       "      <td>-1.160667</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.287133</td>\n",
       "      <td>0.398933</td>\n",
       "      <td>0.393867</td>\n",
       "      <td>-0.107867</td>\n",
       "      <td>0.436600</td>\n",
       "      <td>-2.651333</td>\n",
       "      <td>1.295333</td>\n",
       "      <td>-0.641333</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.057333</td>\n",
       "      <td>-0.360667</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.701333</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>-1.461333</td>\n",
       "      <td>2.642667</td>\n",
       "      <td>0.057333</td>\n",
       "      <td>0.980667</td>\n",
       "      <td>-0.561333</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.161333</td>\n",
       "      <td>-0.530333</td>\n",
       "      <td>0.099267</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>-0.134867</td>\n",
       "      <td>-0.171800</td>\n",
       "      <td>0.672400</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>0.254533</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>-0.598000</td>\n",
       "      <td>-0.156000</td>\n",
       "      <td>0.324667</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.052667</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>-0.124667</td>\n",
       "      <td>-0.518667</td>\n",
       "      <td>-0.225333</td>\n",
       "      <td>0.254667</td>\n",
       "      <td>0.089333</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RLFNKKKELGQDKMQ</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.211333</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.107333</td>\n",
       "      <td>-0.269333</td>\n",
       "      <td>0.275333</td>\n",
       "      <td>-0.280667</td>\n",
       "      <td>0.609333</td>\n",
       "      <td>0.388667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.849333</td>\n",
       "      <td>0.328667</td>\n",
       "      <td>-0.971333</td>\n",
       "      <td>-0.077333</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.103867</td>\n",
       "      <td>0.255533</td>\n",
       "      <td>-0.080400</td>\n",
       "      <td>0.185867</td>\n",
       "      <td>-3.426000</td>\n",
       "      <td>1.287333</td>\n",
       "      <td>-0.558000</td>\n",
       "      <td>0.219333</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>-0.422667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.423333</td>\n",
       "      <td>0.219333</td>\n",
       "      <td>0.229333</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>-0.210000</td>\n",
       "      <td>-1.970000</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>-0.234000</td>\n",
       "      <td>0.471333</td>\n",
       "      <td>-0.396667</td>\n",
       "      <td>0.691333</td>\n",
       "      <td>-0.155333</td>\n",
       "      <td>0.212667</td>\n",
       "      <td>-0.668733</td>\n",
       "      <td>0.094133</td>\n",
       "      <td>0.040467</td>\n",
       "      <td>-0.046800</td>\n",
       "      <td>-0.095933</td>\n",
       "      <td>0.429200</td>\n",
       "      <td>0.205933</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>-0.002667</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>-0.298000</td>\n",
       "      <td>0.240667</td>\n",
       "      <td>0.248667</td>\n",
       "      <td>-0.038000</td>\n",
       "      <td>0.193333</td>\n",
       "      <td>-0.021333</td>\n",
       "      <td>-0.228667</td>\n",
       "      <td>-0.193333</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>-0.039333</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YKLKLDRLFNKKKEL</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.161333</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>0.515333</td>\n",
       "      <td>-0.240667</td>\n",
       "      <td>0.451333</td>\n",
       "      <td>0.131333</td>\n",
       "      <td>-1.094000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.439333</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>-1.170667</td>\n",
       "      <td>0.032667</td>\n",
       "      <td>0.317333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479333</td>\n",
       "      <td>0.431267</td>\n",
       "      <td>0.539267</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.303533</td>\n",
       "      <td>-2.664667</td>\n",
       "      <td>1.235333</td>\n",
       "      <td>-0.604667</td>\n",
       "      <td>0.221333</td>\n",
       "      <td>0.039333</td>\n",
       "      <td>-0.204667</td>\n",
       "      <td>0.567333</td>\n",
       "      <td>0.508667</td>\n",
       "      <td>0.245333</td>\n",
       "      <td>0.401333</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>-0.129333</td>\n",
       "      <td>-0.759333</td>\n",
       "      <td>2.313333</td>\n",
       "      <td>-0.352000</td>\n",
       "      <td>0.681333</td>\n",
       "      <td>-0.817333</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.169333</td>\n",
       "      <td>0.111333</td>\n",
       "      <td>-0.534533</td>\n",
       "      <td>0.035467</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>-0.144600</td>\n",
       "      <td>-0.206467</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>-0.016000</td>\n",
       "      <td>-0.644667</td>\n",
       "      <td>-0.202000</td>\n",
       "      <td>0.245333</td>\n",
       "      <td>0.175333</td>\n",
       "      <td>-0.019333</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>-0.034667</td>\n",
       "      <td>-0.434000</td>\n",
       "      <td>-0.234000</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              PP1       PP2       PP3       KF1       KF2       KF3       KF4       KF5       KF6       KF7       KF8       KF9      KF10        Z1        Z2        Z3        Z4        Z5  F1        F2        F3        F4        F5        F6        T1        T2        T3        T4        T5     VHSE1     VHSE2     VHSE3     VHSE4     VHSE5     VHSE6     VHSE7     VHSE8   ProtFP1   ProtFP2   ProtFP3   ProtFP4   ProtFP5   ProtFP6   ProtFP7   ProtFP8       ST1       ST2       ST3       ST4       ST5       ST6       ST7       ST8   BLOSUM1   BLOSUM2   BLOSUM3   BLOSUM4   BLOSUM5   BLOSUM6   BLOSUM7   BLOSUM8   BLOSUM9  BLOSUM10   MSWHIM1   MSWHIM2   MSWHIM3     Class\n",
       "ID              Epitope                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "LDRLFNKKKELGQDK E-10004  0.220667 -0.172667  0.055333 -0.175333  0.232667 -0.378667  0.565333  0.084000 -0.762000  0.542667  0.154000  0.130000  0.224000  0.902667  0.285333 -0.877333 -0.329333  0.407333 NaN  0.271067  0.096267  0.462000 -0.059733  0.049667 -3.556000  1.176000 -0.360667  0.206000  0.384000 -0.412000  0.360000  0.169333  0.358667  0.034000  0.190667  0.682667 -0.141333 -2.104000  1.502667 -0.427333  0.163333 -0.546667  0.634667  0.050000  0.165333 -0.693933  0.016867 -0.040067 -0.090733 -0.075400  0.401733  0.146333  0.395867  0.516667 -0.040000 -0.415333 -0.193333  0.127333  0.252667 -0.113333  0.211333 -0.048667 -0.317333 -0.208667  0.142000 -0.072667  Negative\n",
       "LKLDRLFNKKKELGQ E-10004  0.094000 -0.111333  0.106000 -0.283333  0.247333 -0.289333  0.438000  0.108667       NaN  0.708000  0.072000       NaN       NaN  0.352000  0.136667 -1.105333 -0.213333  0.413333 NaN  0.375867  0.182067  0.600600 -0.006733  0.157733 -3.538000  1.144667 -0.486000  0.329333  0.315333 -0.244667  0.320000  0.220667  0.306000  0.227333  0.012000  0.686000 -0.220000 -1.279333  1.351333 -0.338667  0.510667 -0.692000  0.769333  0.040000  0.068667 -0.688533 -0.004800  0.014533 -0.078133 -0.191733  0.463333  0.147400  0.392267  0.319333 -0.098000 -0.495333 -0.237333  0.195333  0.274667  0.002000  0.186000 -0.068000 -0.300000 -0.265333  0.256667 -0.019333  Negative\n",
       "NKYKLKLDRLFNKKK E-10004  0.253333  0.012667  0.302000 -0.060667  0.552667 -0.140667  0.614000  0.370000 -1.067333  0.624000  0.127333  0.221333  0.310000  0.516000  0.832667 -1.160667  0.306000  0.406000 NaN  0.287133  0.398933  0.393867 -0.107867  0.436600 -2.651333  1.295333 -0.641333  0.176000  0.057333 -0.360667  0.582667  0.500000  0.374000  0.603333  0.328000  0.701333 -0.134000 -1.461333  2.642667  0.057333  0.980667 -0.561333  0.526667  0.283333  0.161333 -0.530333  0.099267  0.132000 -0.134867 -0.171800  0.672400  0.115867  0.254533  0.362000  0.038000 -0.598000 -0.156000  0.324667  0.220000  0.052667  0.043333 -0.124667 -0.518667 -0.225333  0.254667  0.089333  Negative\n",
       "RLFNKKKELGQDKMQ E-10004  0.211333 -0.133333  0.107333 -0.269333  0.275333 -0.280667  0.609333  0.388667       NaN  0.653333  0.133333       NaN       NaN  0.849333  0.328667 -0.971333 -0.077333  0.280000 NaN  0.340600  0.103867  0.255533 -0.080400  0.185867 -3.426000  1.287333 -0.558000  0.219333  0.282000 -0.422667  0.283333  0.213333  0.423333  0.219333  0.229333  0.604667 -0.210000 -1.970000  1.733333 -0.234000  0.471333 -0.396667  0.691333 -0.155333  0.212667 -0.668733  0.094133  0.040467 -0.046800 -0.095933  0.429200  0.205933  0.384800  0.516000 -0.002667 -0.500667 -0.298000  0.240667  0.248667 -0.038000  0.193333 -0.021333 -0.228667 -0.193333  0.294000 -0.039333  Negative\n",
       "YKLKLDRLFNKKKEL E-10004  0.161333  0.010000  0.152000 -0.280000  0.515333 -0.240667  0.451333  0.131333 -1.094000  0.620000  0.025333  0.186667  0.439333  0.082000  0.596000 -1.170667  0.032667  0.317333 NaN  0.479333  0.431267  0.539267  0.003333  0.303533 -2.664667  1.235333 -0.604667  0.221333  0.039333 -0.204667  0.567333  0.508667  0.245333  0.401333  0.124000  0.610000 -0.129333 -0.759333  2.313333 -0.352000  0.681333 -0.817333  0.613333  0.169333  0.111333 -0.534533  0.035467  0.132800 -0.144600 -0.206467  0.696667  0.086600  0.244600  0.190000 -0.016000 -0.644667 -0.202000  0.245333  0.175333 -0.019333  0.106667 -0.034667 -0.434000 -0.234000  0.258000  0.080000  Negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"CW_ModelDevelopment.csv\", index_col=[0,1])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 67)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pre-processing</h2>\n",
    "<h4>Remove or predict missing data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014321969100638"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "data = pd.read_csv(\"CW_ModelDevelopment.csv\", index_col=[0,1])\n",
    "\n",
    "cols = [\"ProtFP2\", \"MSWHIM3\", \"ST6\", \"BLOSUM3\", \"PP1\", \"T2\"]\n",
    "\n",
    "new = data[cols]\n",
    "\n",
    "test = new[new[\"T2\"].isnull()]\n",
    "train = new.dropna()\n",
    "\n",
    "X = train.drop(\"T2\", axis=1)\n",
    "y = train[\"T2\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "missing = test.drop(\"T2\", axis=1)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2877: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  result = self._run_cell(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PP1</th>\n",
       "      <th>PP2</th>\n",
       "      <th>PP3</th>\n",
       "      <th>KF1</th>\n",
       "      <th>KF2</th>\n",
       "      <th>KF3</th>\n",
       "      <th>KF4</th>\n",
       "      <th>KF5</th>\n",
       "      <th>KF7</th>\n",
       "      <th>KF8</th>\n",
       "      <th>Z1</th>\n",
       "      <th>Z2</th>\n",
       "      <th>Z3</th>\n",
       "      <th>Z4</th>\n",
       "      <th>Z5</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>VHSE1</th>\n",
       "      <th>VHSE2</th>\n",
       "      <th>VHSE3</th>\n",
       "      <th>VHSE4</th>\n",
       "      <th>VHSE5</th>\n",
       "      <th>VHSE6</th>\n",
       "      <th>VHSE7</th>\n",
       "      <th>VHSE8</th>\n",
       "      <th>ProtFP1</th>\n",
       "      <th>ProtFP2</th>\n",
       "      <th>ProtFP3</th>\n",
       "      <th>ProtFP4</th>\n",
       "      <th>ProtFP5</th>\n",
       "      <th>ProtFP6</th>\n",
       "      <th>ProtFP7</th>\n",
       "      <th>ProtFP8</th>\n",
       "      <th>ST1</th>\n",
       "      <th>ST2</th>\n",
       "      <th>ST3</th>\n",
       "      <th>ST4</th>\n",
       "      <th>ST5</th>\n",
       "      <th>ST6</th>\n",
       "      <th>ST7</th>\n",
       "      <th>ST8</th>\n",
       "      <th>BLOSUM1</th>\n",
       "      <th>BLOSUM2</th>\n",
       "      <th>BLOSUM3</th>\n",
       "      <th>BLOSUM4</th>\n",
       "      <th>BLOSUM5</th>\n",
       "      <th>BLOSUM6</th>\n",
       "      <th>BLOSUM7</th>\n",
       "      <th>BLOSUM8</th>\n",
       "      <th>BLOSUM9</th>\n",
       "      <th>BLOSUM10</th>\n",
       "      <th>MSWHIM1</th>\n",
       "      <th>MSWHIM2</th>\n",
       "      <th>MSWHIM3</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>Epitope</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LDRLFNKKKELGQDK</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.220667</td>\n",
       "      <td>-0.172667</td>\n",
       "      <td>0.055333</td>\n",
       "      <td>-0.175333</td>\n",
       "      <td>0.232667</td>\n",
       "      <td>-0.378667</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>0.285333</td>\n",
       "      <td>-0.877333</td>\n",
       "      <td>-0.329333</td>\n",
       "      <td>0.407333</td>\n",
       "      <td>0.271067</td>\n",
       "      <td>0.096267</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>-0.059733</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>-3.556000</td>\n",
       "      <td>1.176000</td>\n",
       "      <td>-0.360667</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>-0.412000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.169333</td>\n",
       "      <td>0.358667</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>0.682667</td>\n",
       "      <td>-0.141333</td>\n",
       "      <td>-2.104000</td>\n",
       "      <td>1.502667</td>\n",
       "      <td>-0.427333</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>-0.546667</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.165333</td>\n",
       "      <td>-0.693933</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>-0.040067</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.075400</td>\n",
       "      <td>0.401733</td>\n",
       "      <td>0.146333</td>\n",
       "      <td>0.395867</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>-0.415333</td>\n",
       "      <td>-0.193333</td>\n",
       "      <td>0.127333</td>\n",
       "      <td>0.252667</td>\n",
       "      <td>-0.113333</td>\n",
       "      <td>0.211333</td>\n",
       "      <td>-0.048667</td>\n",
       "      <td>-0.317333</td>\n",
       "      <td>-0.208667</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>-0.072667</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LKLDRLFNKKKELGQ</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.094000</td>\n",
       "      <td>-0.111333</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>-0.283333</td>\n",
       "      <td>0.247333</td>\n",
       "      <td>-0.289333</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.108667</td>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>-1.105333</td>\n",
       "      <td>-0.213333</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.375867</td>\n",
       "      <td>0.182067</td>\n",
       "      <td>0.600600</td>\n",
       "      <td>-0.006733</td>\n",
       "      <td>0.157733</td>\n",
       "      <td>-3.538000</td>\n",
       "      <td>1.144667</td>\n",
       "      <td>-0.486000</td>\n",
       "      <td>0.329333</td>\n",
       "      <td>0.315333</td>\n",
       "      <td>-0.244667</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.220667</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.227333</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>-1.279333</td>\n",
       "      <td>1.351333</td>\n",
       "      <td>-0.338667</td>\n",
       "      <td>0.510667</td>\n",
       "      <td>-0.692000</td>\n",
       "      <td>0.769333</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>-0.688533</td>\n",
       "      <td>-0.004800</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>-0.078133</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.392267</td>\n",
       "      <td>0.319333</td>\n",
       "      <td>-0.098000</td>\n",
       "      <td>-0.495333</td>\n",
       "      <td>-0.237333</td>\n",
       "      <td>0.195333</td>\n",
       "      <td>0.274667</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>-0.068000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.265333</td>\n",
       "      <td>0.256667</td>\n",
       "      <td>-0.019333</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NKYKLKLDRLFNKKK</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>-0.060667</td>\n",
       "      <td>0.552667</td>\n",
       "      <td>-0.140667</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.127333</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.832667</td>\n",
       "      <td>-1.160667</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>0.287133</td>\n",
       "      <td>0.398933</td>\n",
       "      <td>0.393867</td>\n",
       "      <td>-0.107867</td>\n",
       "      <td>0.436600</td>\n",
       "      <td>-2.651333</td>\n",
       "      <td>1.295333</td>\n",
       "      <td>-0.641333</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.057333</td>\n",
       "      <td>-0.360667</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.701333</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>-1.461333</td>\n",
       "      <td>2.642667</td>\n",
       "      <td>0.057333</td>\n",
       "      <td>0.980667</td>\n",
       "      <td>-0.561333</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.161333</td>\n",
       "      <td>-0.530333</td>\n",
       "      <td>0.099267</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>-0.134867</td>\n",
       "      <td>-0.171800</td>\n",
       "      <td>0.672400</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>0.254533</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>-0.598000</td>\n",
       "      <td>-0.156000</td>\n",
       "      <td>0.324667</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.052667</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>-0.124667</td>\n",
       "      <td>-0.518667</td>\n",
       "      <td>-0.225333</td>\n",
       "      <td>0.254667</td>\n",
       "      <td>0.089333</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RLFNKKKELGQDKMQ</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.211333</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.107333</td>\n",
       "      <td>-0.269333</td>\n",
       "      <td>0.275333</td>\n",
       "      <td>-0.280667</td>\n",
       "      <td>0.609333</td>\n",
       "      <td>0.388667</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.849333</td>\n",
       "      <td>0.328667</td>\n",
       "      <td>-0.971333</td>\n",
       "      <td>-0.077333</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.103867</td>\n",
       "      <td>0.255533</td>\n",
       "      <td>-0.080400</td>\n",
       "      <td>0.185867</td>\n",
       "      <td>-3.426000</td>\n",
       "      <td>1.287333</td>\n",
       "      <td>-0.558000</td>\n",
       "      <td>0.219333</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>-0.422667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.423333</td>\n",
       "      <td>0.219333</td>\n",
       "      <td>0.229333</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>-0.210000</td>\n",
       "      <td>-1.970000</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>-0.234000</td>\n",
       "      <td>0.471333</td>\n",
       "      <td>-0.396667</td>\n",
       "      <td>0.691333</td>\n",
       "      <td>-0.155333</td>\n",
       "      <td>0.212667</td>\n",
       "      <td>-0.668733</td>\n",
       "      <td>0.094133</td>\n",
       "      <td>0.040467</td>\n",
       "      <td>-0.046800</td>\n",
       "      <td>-0.095933</td>\n",
       "      <td>0.429200</td>\n",
       "      <td>0.205933</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>-0.002667</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>-0.298000</td>\n",
       "      <td>0.240667</td>\n",
       "      <td>0.248667</td>\n",
       "      <td>-0.038000</td>\n",
       "      <td>0.193333</td>\n",
       "      <td>-0.021333</td>\n",
       "      <td>-0.228667</td>\n",
       "      <td>-0.193333</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>-0.039333</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YKLKLDRLFNKKKEL</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.161333</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>0.515333</td>\n",
       "      <td>-0.240667</td>\n",
       "      <td>0.451333</td>\n",
       "      <td>0.131333</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>-1.170667</td>\n",
       "      <td>0.032667</td>\n",
       "      <td>0.317333</td>\n",
       "      <td>0.479333</td>\n",
       "      <td>0.431267</td>\n",
       "      <td>0.539267</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.303533</td>\n",
       "      <td>-2.664667</td>\n",
       "      <td>1.235333</td>\n",
       "      <td>-0.604667</td>\n",
       "      <td>0.221333</td>\n",
       "      <td>0.039333</td>\n",
       "      <td>-0.204667</td>\n",
       "      <td>0.567333</td>\n",
       "      <td>0.508667</td>\n",
       "      <td>0.245333</td>\n",
       "      <td>0.401333</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>-0.129333</td>\n",
       "      <td>-0.759333</td>\n",
       "      <td>2.313333</td>\n",
       "      <td>-0.352000</td>\n",
       "      <td>0.681333</td>\n",
       "      <td>-0.817333</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.169333</td>\n",
       "      <td>0.111333</td>\n",
       "      <td>-0.534533</td>\n",
       "      <td>0.035467</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>-0.144600</td>\n",
       "      <td>-0.206467</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>-0.016000</td>\n",
       "      <td>-0.644667</td>\n",
       "      <td>-0.202000</td>\n",
       "      <td>0.245333</td>\n",
       "      <td>0.175333</td>\n",
       "      <td>-0.019333</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>-0.034667</td>\n",
       "      <td>-0.434000</td>\n",
       "      <td>-0.234000</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DGNNEDNEKLRKPKH</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.468000</td>\n",
       "      <td>-0.341333</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>0.112667</td>\n",
       "      <td>-0.530667</td>\n",
       "      <td>0.775333</td>\n",
       "      <td>0.069333</td>\n",
       "      <td>0.124667</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>2.153333</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>-0.216000</td>\n",
       "      <td>-0.328667</td>\n",
       "      <td>0.609333</td>\n",
       "      <td>-0.100200</td>\n",
       "      <td>-0.222933</td>\n",
       "      <td>0.076933</td>\n",
       "      <td>0.094867</td>\n",
       "      <td>-0.264800</td>\n",
       "      <td>-3.858000</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>-0.005333</td>\n",
       "      <td>-0.116667</td>\n",
       "      <td>0.522000</td>\n",
       "      <td>-0.777333</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>-0.052667</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>-0.311333</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.872667</td>\n",
       "      <td>0.148667</td>\n",
       "      <td>-3.960667</td>\n",
       "      <td>1.339333</td>\n",
       "      <td>-0.160667</td>\n",
       "      <td>-0.136000</td>\n",
       "      <td>-0.381333</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>-0.489333</td>\n",
       "      <td>-0.750067</td>\n",
       "      <td>-0.002400</td>\n",
       "      <td>-0.235400</td>\n",
       "      <td>-0.183333</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>0.143067</td>\n",
       "      <td>0.229133</td>\n",
       "      <td>0.273133</td>\n",
       "      <td>1.070667</td>\n",
       "      <td>0.092667</td>\n",
       "      <td>-0.245333</td>\n",
       "      <td>0.048667</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.104667</td>\n",
       "      <td>-0.082000</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>-0.205333</td>\n",
       "      <td>-0.169333</td>\n",
       "      <td>-0.084667</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>-0.231333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDKRDGNNEDNEKLR</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>-0.367333</td>\n",
       "      <td>-0.112000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>-0.541333</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>-0.461333</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>2.654000</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>-0.302000</td>\n",
       "      <td>-0.968667</td>\n",
       "      <td>0.471333</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>-0.231333</td>\n",
       "      <td>0.137733</td>\n",
       "      <td>-0.142867</td>\n",
       "      <td>-0.301800</td>\n",
       "      <td>-3.774000</td>\n",
       "      <td>1.414667</td>\n",
       "      <td>0.191333</td>\n",
       "      <td>-0.090667</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>-0.938667</td>\n",
       "      <td>0.403333</td>\n",
       "      <td>-0.028667</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>-0.673333</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>-0.046667</td>\n",
       "      <td>-4.351333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-0.878667</td>\n",
       "      <td>-0.768000</td>\n",
       "      <td>-0.161333</td>\n",
       "      <td>0.408667</td>\n",
       "      <td>0.177333</td>\n",
       "      <td>-0.344667</td>\n",
       "      <td>-0.737867</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>-0.334267</td>\n",
       "      <td>-0.152800</td>\n",
       "      <td>0.358867</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.191267</td>\n",
       "      <td>0.372333</td>\n",
       "      <td>1.157333</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>-0.244667</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.015333</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>-0.328000</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>-0.069333</td>\n",
       "      <td>-0.162000</td>\n",
       "      <td>-0.179333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDNEKLRKPKHKKLK</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.410667</td>\n",
       "      <td>-0.117333</td>\n",
       "      <td>0.256667</td>\n",
       "      <td>-0.228667</td>\n",
       "      <td>0.431333</td>\n",
       "      <td>-0.456000</td>\n",
       "      <td>0.890667</td>\n",
       "      <td>0.371333</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>-0.117333</td>\n",
       "      <td>1.517333</td>\n",
       "      <td>0.702000</td>\n",
       "      <td>-1.104667</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.392133</td>\n",
       "      <td>0.087333</td>\n",
       "      <td>0.253133</td>\n",
       "      <td>0.260267</td>\n",
       "      <td>0.231733</td>\n",
       "      <td>-3.034667</td>\n",
       "      <td>1.246000</td>\n",
       "      <td>-0.615333</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.070667</td>\n",
       "      <td>-0.698667</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.407333</td>\n",
       "      <td>0.318667</td>\n",
       "      <td>0.300667</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>-3.103333</td>\n",
       "      <td>2.661333</td>\n",
       "      <td>-0.229333</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>-0.916000</td>\n",
       "      <td>0.497333</td>\n",
       "      <td>-0.063333</td>\n",
       "      <td>-0.146000</td>\n",
       "      <td>-0.604133</td>\n",
       "      <td>0.033733</td>\n",
       "      <td>-0.022333</td>\n",
       "      <td>-0.193400</td>\n",
       "      <td>-0.050867</td>\n",
       "      <td>0.606133</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>0.234133</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>-0.014000</td>\n",
       "      <td>-0.594000</td>\n",
       "      <td>-0.306000</td>\n",
       "      <td>0.262667</td>\n",
       "      <td>-0.043333</td>\n",
       "      <td>-0.001333</td>\n",
       "      <td>0.100667</td>\n",
       "      <td>-0.029333</td>\n",
       "      <td>-0.319333</td>\n",
       "      <td>-0.241333</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KRDGNNEDNEKLRKP</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.476667</td>\n",
       "      <td>-0.292000</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>0.162667</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>-0.151333</td>\n",
       "      <td>0.309333</td>\n",
       "      <td>0.244667</td>\n",
       "      <td>2.223333</td>\n",
       "      <td>0.654667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.456000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>-0.105733</td>\n",
       "      <td>-0.186933</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>0.091333</td>\n",
       "      <td>-0.094200</td>\n",
       "      <td>-3.775333</td>\n",
       "      <td>1.163333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.022000</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>-0.846667</td>\n",
       "      <td>0.367333</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>-0.242000</td>\n",
       "      <td>0.392667</td>\n",
       "      <td>0.897333</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>-4.158000</td>\n",
       "      <td>1.636667</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>-0.347333</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.189333</td>\n",
       "      <td>-0.282000</td>\n",
       "      <td>-0.739000</td>\n",
       "      <td>0.022267</td>\n",
       "      <td>-0.241533</td>\n",
       "      <td>-0.120600</td>\n",
       "      <td>0.161867</td>\n",
       "      <td>0.144867</td>\n",
       "      <td>0.232333</td>\n",
       "      <td>0.330133</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>-0.249333</td>\n",
       "      <td>-0.095333</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.170667</td>\n",
       "      <td>-0.082000</td>\n",
       "      <td>0.099333</td>\n",
       "      <td>-0.207333</td>\n",
       "      <td>-0.270000</td>\n",
       "      <td>-0.155333</td>\n",
       "      <td>-0.015333</td>\n",
       "      <td>-0.112667</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNEDNEKLRKPKHKK</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>-0.202000</td>\n",
       "      <td>0.208667</td>\n",
       "      <td>0.015333</td>\n",
       "      <td>0.367333</td>\n",
       "      <td>-0.440667</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.329333</td>\n",
       "      <td>0.291333</td>\n",
       "      <td>0.102667</td>\n",
       "      <td>2.056667</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>-0.700667</td>\n",
       "      <td>0.088667</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.153600</td>\n",
       "      <td>-0.035600</td>\n",
       "      <td>0.051067</td>\n",
       "      <td>0.163933</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-3.186000</td>\n",
       "      <td>1.353294</td>\n",
       "      <td>-0.315333</td>\n",
       "      <td>-0.085333</td>\n",
       "      <td>0.207333</td>\n",
       "      <td>-0.843333</td>\n",
       "      <td>0.404667</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.499333</td>\n",
       "      <td>0.121333</td>\n",
       "      <td>0.460667</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>-3.805333</td>\n",
       "      <td>2.524667</td>\n",
       "      <td>-0.143333</td>\n",
       "      <td>0.659333</td>\n",
       "      <td>-0.556667</td>\n",
       "      <td>0.269333</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>-0.428667</td>\n",
       "      <td>-0.633867</td>\n",
       "      <td>0.035067</td>\n",
       "      <td>-0.131467</td>\n",
       "      <td>-0.213667</td>\n",
       "      <td>0.138867</td>\n",
       "      <td>0.492267</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.183733</td>\n",
       "      <td>1.062667</td>\n",
       "      <td>0.075333</td>\n",
       "      <td>-0.488667</td>\n",
       "      <td>-0.103333</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>-0.026667</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>-0.172000</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>-0.139333</td>\n",
       "      <td>0.107333</td>\n",
       "      <td>-0.037333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14919 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              PP1       PP2       PP3       KF1       KF2       KF3       KF4       KF5       KF7       KF8        Z1        Z2        Z3        Z4        Z5        F2        F3        F4        F5        F6        T1        T2        T3        T4        T5     VHSE1     VHSE2     VHSE3     VHSE4     VHSE5     VHSE6     VHSE7     VHSE8   ProtFP1   ProtFP2   ProtFP3   ProtFP4   ProtFP5   ProtFP6   ProtFP7   ProtFP8       ST1       ST2       ST3       ST4       ST5       ST6       ST7       ST8   BLOSUM1   BLOSUM2   BLOSUM3   BLOSUM4   BLOSUM5   BLOSUM6   BLOSUM7   BLOSUM8   BLOSUM9  BLOSUM10   MSWHIM1   MSWHIM2   MSWHIM3     Class\n",
       "ID              Epitope                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "LDRLFNKKKELGQDK E-10004  0.220667 -0.172667  0.055333 -0.175333  0.232667 -0.378667  0.565333  0.084000  0.542667  0.154000  0.902667  0.285333 -0.877333 -0.329333  0.407333  0.271067  0.096267  0.462000 -0.059733  0.049667 -3.556000  1.176000 -0.360667  0.206000  0.384000 -0.412000  0.360000  0.169333  0.358667  0.034000  0.190667  0.682667 -0.141333 -2.104000  1.502667 -0.427333  0.163333 -0.546667  0.634667  0.050000  0.165333 -0.693933  0.016867 -0.040067 -0.090733 -0.075400  0.401733  0.146333  0.395867  0.516667 -0.040000 -0.415333 -0.193333  0.127333  0.252667 -0.113333  0.211333 -0.048667 -0.317333 -0.208667  0.142000 -0.072667  Negative\n",
       "LKLDRLFNKKKELGQ E-10004  0.094000 -0.111333  0.106000 -0.283333  0.247333 -0.289333  0.438000  0.108667  0.708000  0.072000  0.352000  0.136667 -1.105333 -0.213333  0.413333  0.375867  0.182067  0.600600 -0.006733  0.157733 -3.538000  1.144667 -0.486000  0.329333  0.315333 -0.244667  0.320000  0.220667  0.306000  0.227333  0.012000  0.686000 -0.220000 -1.279333  1.351333 -0.338667  0.510667 -0.692000  0.769333  0.040000  0.068667 -0.688533 -0.004800  0.014533 -0.078133 -0.191733  0.463333  0.147400  0.392267  0.319333 -0.098000 -0.495333 -0.237333  0.195333  0.274667  0.002000  0.186000 -0.068000 -0.300000 -0.265333  0.256667 -0.019333  Negative\n",
       "NKYKLKLDRLFNKKK E-10004  0.253333  0.012667  0.302000 -0.060667  0.552667 -0.140667  0.614000  0.370000  0.624000  0.127333  0.516000  0.832667 -1.160667  0.306000  0.406000  0.287133  0.398933  0.393867 -0.107867  0.436600 -2.651333  1.295333 -0.641333  0.176000  0.057333 -0.360667  0.582667  0.500000  0.374000  0.603333  0.328000  0.701333 -0.134000 -1.461333  2.642667  0.057333  0.980667 -0.561333  0.526667  0.283333  0.161333 -0.530333  0.099267  0.132000 -0.134867 -0.171800  0.672400  0.115867  0.254533  0.362000  0.038000 -0.598000 -0.156000  0.324667  0.220000  0.052667  0.043333 -0.124667 -0.518667 -0.225333  0.254667  0.089333  Negative\n",
       "RLFNKKKELGQDKMQ E-10004  0.211333 -0.133333  0.107333 -0.269333  0.275333 -0.280667  0.609333  0.388667  0.653333  0.133333  0.849333  0.328667 -0.971333 -0.077333  0.280000  0.340600  0.103867  0.255533 -0.080400  0.185867 -3.426000  1.287333 -0.558000  0.219333  0.282000 -0.422667  0.283333  0.213333  0.423333  0.219333  0.229333  0.604667 -0.210000 -1.970000  1.733333 -0.234000  0.471333 -0.396667  0.691333 -0.155333  0.212667 -0.668733  0.094133  0.040467 -0.046800 -0.095933  0.429200  0.205933  0.384800  0.516000 -0.002667 -0.500667 -0.298000  0.240667  0.248667 -0.038000  0.193333 -0.021333 -0.228667 -0.193333  0.294000 -0.039333  Negative\n",
       "YKLKLDRLFNKKKEL E-10004  0.161333  0.010000  0.152000 -0.280000  0.515333 -0.240667  0.451333  0.131333  0.620000  0.025333  0.082000  0.596000 -1.170667  0.032667  0.317333  0.479333  0.431267  0.539267  0.003333  0.303533 -2.664667  1.235333 -0.604667  0.221333  0.039333 -0.204667  0.567333  0.508667  0.245333  0.401333  0.124000  0.610000 -0.129333 -0.759333  2.313333 -0.352000  0.681333 -0.817333  0.613333  0.169333  0.111333 -0.534533  0.035467  0.132800 -0.144600 -0.206467  0.696667  0.086600  0.244600  0.190000 -0.016000 -0.644667 -0.202000  0.245333  0.175333 -0.019333  0.106667 -0.034667 -0.434000 -0.234000  0.258000  0.080000  Negative\n",
       "...                           ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...\n",
       "DGNNEDNEKLRKPKH E-43575  0.468000 -0.341333  0.041333  0.196667  0.112667 -0.530667  0.775333  0.069333  0.124667  0.302000  2.153333  0.618000 -0.216000 -0.328667  0.609333 -0.100200 -0.222933  0.076933  0.094867 -0.264800 -3.858000  0.816667 -0.005333 -0.116667  0.522000 -0.777333  0.254000 -0.052667  0.544000 -0.311333  0.380000  0.872667  0.148667 -3.960667  1.339333 -0.160667 -0.136000 -0.381333  0.188000  0.066000 -0.489333 -0.750067 -0.002400 -0.235400 -0.183333  0.216600  0.143067  0.229133  0.273133  1.070667  0.092667 -0.245333  0.048667  0.010000  0.104667 -0.082000  0.082000 -0.205333 -0.169333 -0.084667  0.011333 -0.231333  Positive\n",
       "EDKRDGNNEDNEKLR E-43575  0.620000 -0.367333 -0.112000  0.066000  0.128000 -0.541333  0.950000 -0.461333  0.114000  0.460000  2.654000  0.656667 -0.302000 -0.968667  0.471333  0.054933 -0.231333  0.137733 -0.142867 -0.301800 -3.774000  1.414667  0.191333 -0.090667  0.664000 -0.938667  0.403333 -0.028667  0.582667 -0.673333  0.513333  0.864000 -0.046667 -4.351333  1.666667 -0.878667 -0.768000 -0.161333  0.408667  0.177333 -0.344667 -0.737867  0.003467 -0.334267 -0.152800  0.358867  0.177800  0.191267  0.372333  1.157333  0.066000 -0.244667  0.028000  0.015333  0.294000 -0.328000  0.173333 -0.150000 -0.192000 -0.069333 -0.162000 -0.179333  Positive\n",
       "EDNEKLRKPKHKKLK E-43575  0.410667 -0.117333  0.256667 -0.228667  0.431333 -0.456000  0.890667  0.371333  0.444000 -0.117333  1.517333  0.702000 -1.104667  0.293333  0.488000  0.392133  0.087333  0.253133  0.260267  0.231733 -3.034667  1.246000 -0.615333  0.068000  0.070667 -0.698667  0.456000  0.363333  0.407333  0.318667  0.300667  0.970667  0.292000 -3.103333  2.661333 -0.229333  0.920000 -0.916000  0.497333 -0.063333 -0.146000 -0.604133  0.033733 -0.022333 -0.193400 -0.050867  0.606133  0.342800  0.234133  0.843333 -0.014000 -0.594000 -0.306000  0.262667 -0.043333 -0.001333  0.100667 -0.029333 -0.319333 -0.241333  0.134000  0.080000  Positive\n",
       "KRDGNNEDNEKLRKP E-43575  0.476667 -0.292000  0.082667  0.238667  0.162667 -0.420667  0.881333 -0.151333  0.309333  0.244667  2.223333  0.654667 -0.466667 -0.456000  0.592000 -0.105733 -0.186933  0.148867  0.091333 -0.094200 -3.775333  1.163333 -0.083333 -0.022000  0.532000 -0.846667  0.367333  0.005333  0.616000 -0.242000  0.392667  0.897333  0.160667 -4.158000  1.636667 -0.160000 -0.045333 -0.347333  0.264000  0.189333 -0.282000 -0.739000  0.022267 -0.241533 -0.120600  0.161867  0.144867  0.232333  0.330133  1.090000  0.002000 -0.249333 -0.095333  0.072000  0.170667 -0.082000  0.099333 -0.207333 -0.270000 -0.155333 -0.015333 -0.112667  Positive\n",
       "NNEDNEKLRKPKHKK E-43575  0.540000 -0.202000  0.208667  0.015333  0.367333 -0.440667  0.958667  0.329333  0.291333  0.102667  2.056667  0.945333 -0.700667  0.088667  0.626000  0.153600 -0.035600  0.051067  0.163933  0.083333 -3.186000  1.353294 -0.315333 -0.085333  0.207333 -0.843333  0.404667  0.243333  0.499333  0.121333  0.460667  0.954000  0.218000 -3.805333  2.524667 -0.143333  0.659333 -0.556667  0.269333  0.063333 -0.428667 -0.633867  0.035067 -0.131467 -0.213667  0.138867  0.492267  0.304400  0.183733  1.062667  0.075333 -0.488667 -0.103333  0.222000  0.038000 -0.026667  0.006000 -0.172000 -0.280000 -0.139333  0.107333 -0.037333  Positive\n",
       "\n",
       "[14919 rows x 63 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace the missing values with predicted values\n",
    "y_pred = lr.predict(missing)\n",
    "data.loc[data.T2.isnull(), 'T2'] = y_pred\n",
    "data = data.drop(columns=[\"F1\",\"KF6\",\"KF9\",\"KF10\"])\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scale Dataframe</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.columns\n",
    "cols = list(cols.drop(\"Class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PP1</th>\n",
       "      <th>PP2</th>\n",
       "      <th>PP3</th>\n",
       "      <th>KF1</th>\n",
       "      <th>KF2</th>\n",
       "      <th>KF3</th>\n",
       "      <th>KF4</th>\n",
       "      <th>KF5</th>\n",
       "      <th>KF7</th>\n",
       "      <th>KF8</th>\n",
       "      <th>Z1</th>\n",
       "      <th>Z2</th>\n",
       "      <th>Z3</th>\n",
       "      <th>Z4</th>\n",
       "      <th>Z5</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>VHSE1</th>\n",
       "      <th>VHSE2</th>\n",
       "      <th>VHSE3</th>\n",
       "      <th>VHSE4</th>\n",
       "      <th>VHSE5</th>\n",
       "      <th>VHSE6</th>\n",
       "      <th>VHSE7</th>\n",
       "      <th>VHSE8</th>\n",
       "      <th>ProtFP1</th>\n",
       "      <th>ProtFP2</th>\n",
       "      <th>ProtFP3</th>\n",
       "      <th>ProtFP4</th>\n",
       "      <th>ProtFP5</th>\n",
       "      <th>ProtFP6</th>\n",
       "      <th>ProtFP7</th>\n",
       "      <th>ProtFP8</th>\n",
       "      <th>ST1</th>\n",
       "      <th>ST2</th>\n",
       "      <th>ST3</th>\n",
       "      <th>ST4</th>\n",
       "      <th>ST5</th>\n",
       "      <th>ST6</th>\n",
       "      <th>ST7</th>\n",
       "      <th>ST8</th>\n",
       "      <th>BLOSUM1</th>\n",
       "      <th>BLOSUM2</th>\n",
       "      <th>BLOSUM3</th>\n",
       "      <th>BLOSUM4</th>\n",
       "      <th>BLOSUM5</th>\n",
       "      <th>BLOSUM6</th>\n",
       "      <th>BLOSUM7</th>\n",
       "      <th>BLOSUM8</th>\n",
       "      <th>BLOSUM9</th>\n",
       "      <th>BLOSUM10</th>\n",
       "      <th>MSWHIM1</th>\n",
       "      <th>MSWHIM2</th>\n",
       "      <th>MSWHIM3</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epitope</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.613005</td>\n",
       "      <td>0.556224</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.783844</td>\n",
       "      <td>0.319924</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.578408</td>\n",
       "      <td>0.832003</td>\n",
       "      <td>0.607354</td>\n",
       "      <td>0.649126</td>\n",
       "      <td>0.678144</td>\n",
       "      <td>0.244074</td>\n",
       "      <td>0.537398</td>\n",
       "      <td>0.542829</td>\n",
       "      <td>0.717201</td>\n",
       "      <td>0.597468</td>\n",
       "      <td>0.641526</td>\n",
       "      <td>0.217876</td>\n",
       "      <td>0.560113</td>\n",
       "      <td>0.673866</td>\n",
       "      <td>0.858511</td>\n",
       "      <td>0.280247</td>\n",
       "      <td>0.524941</td>\n",
       "      <td>0.257035</td>\n",
       "      <td>0.321667</td>\n",
       "      <td>0.747876</td>\n",
       "      <td>0.765465</td>\n",
       "      <td>0.649659</td>\n",
       "      <td>0.68666</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.761518</td>\n",
       "      <td>0.238011</td>\n",
       "      <td>0.339658</td>\n",
       "      <td>0.827053</td>\n",
       "      <td>0.416164</td>\n",
       "      <td>0.607037</td>\n",
       "      <td>0.384237</td>\n",
       "      <td>0.762382</td>\n",
       "      <td>0.538047</td>\n",
       "      <td>0.631182</td>\n",
       "      <td>0.656812</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.621555</td>\n",
       "      <td>0.400266</td>\n",
       "      <td>0.395117</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.502167</td>\n",
       "      <td>0.649828</td>\n",
       "      <td>0.542929</td>\n",
       "      <td>0.224756</td>\n",
       "      <td>0.319087</td>\n",
       "      <td>0.52821</td>\n",
       "      <td>0.728187</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.81889</td>\n",
       "      <td>0.364122</td>\n",
       "      <td>0.242321</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.48431</td>\n",
       "      <td>0.798813</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E-31523</th>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.613005</td>\n",
       "      <td>0.556224</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.783844</td>\n",
       "      <td>0.319924</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.578408</td>\n",
       "      <td>0.832003</td>\n",
       "      <td>0.607354</td>\n",
       "      <td>0.649126</td>\n",
       "      <td>0.678144</td>\n",
       "      <td>0.244074</td>\n",
       "      <td>0.537398</td>\n",
       "      <td>0.542829</td>\n",
       "      <td>0.717201</td>\n",
       "      <td>0.597468</td>\n",
       "      <td>0.641526</td>\n",
       "      <td>0.217876</td>\n",
       "      <td>0.560113</td>\n",
       "      <td>0.673866</td>\n",
       "      <td>0.858511</td>\n",
       "      <td>0.280247</td>\n",
       "      <td>0.524941</td>\n",
       "      <td>0.257035</td>\n",
       "      <td>0.321667</td>\n",
       "      <td>0.747876</td>\n",
       "      <td>0.765465</td>\n",
       "      <td>0.649659</td>\n",
       "      <td>0.68666</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.761518</td>\n",
       "      <td>0.238011</td>\n",
       "      <td>0.339658</td>\n",
       "      <td>0.827053</td>\n",
       "      <td>0.416164</td>\n",
       "      <td>0.607037</td>\n",
       "      <td>0.384237</td>\n",
       "      <td>0.762382</td>\n",
       "      <td>0.538047</td>\n",
       "      <td>0.631182</td>\n",
       "      <td>0.656812</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.621555</td>\n",
       "      <td>0.400266</td>\n",
       "      <td>0.395117</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.502167</td>\n",
       "      <td>0.649828</td>\n",
       "      <td>0.542929</td>\n",
       "      <td>0.224756</td>\n",
       "      <td>0.319087</td>\n",
       "      <td>0.52821</td>\n",
       "      <td>0.728187</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.81889</td>\n",
       "      <td>0.364122</td>\n",
       "      <td>0.242321</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.48431</td>\n",
       "      <td>0.798813</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E-31793</th>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.613005</td>\n",
       "      <td>0.556224</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.783844</td>\n",
       "      <td>0.319924</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.578408</td>\n",
       "      <td>0.832003</td>\n",
       "      <td>0.607354</td>\n",
       "      <td>0.649126</td>\n",
       "      <td>0.678144</td>\n",
       "      <td>0.244074</td>\n",
       "      <td>0.537398</td>\n",
       "      <td>0.542829</td>\n",
       "      <td>0.717201</td>\n",
       "      <td>0.597468</td>\n",
       "      <td>0.641526</td>\n",
       "      <td>0.217876</td>\n",
       "      <td>0.560113</td>\n",
       "      <td>0.673866</td>\n",
       "      <td>0.858511</td>\n",
       "      <td>0.280247</td>\n",
       "      <td>0.524941</td>\n",
       "      <td>0.257035</td>\n",
       "      <td>0.321667</td>\n",
       "      <td>0.747876</td>\n",
       "      <td>0.765465</td>\n",
       "      <td>0.649659</td>\n",
       "      <td>0.68666</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.761518</td>\n",
       "      <td>0.238011</td>\n",
       "      <td>0.339658</td>\n",
       "      <td>0.827053</td>\n",
       "      <td>0.416164</td>\n",
       "      <td>0.607037</td>\n",
       "      <td>0.384237</td>\n",
       "      <td>0.762382</td>\n",
       "      <td>0.538047</td>\n",
       "      <td>0.631182</td>\n",
       "      <td>0.656812</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.621555</td>\n",
       "      <td>0.400266</td>\n",
       "      <td>0.395117</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.502167</td>\n",
       "      <td>0.649828</td>\n",
       "      <td>0.542929</td>\n",
       "      <td>0.224756</td>\n",
       "      <td>0.319087</td>\n",
       "      <td>0.52821</td>\n",
       "      <td>0.728187</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.81889</td>\n",
       "      <td>0.364122</td>\n",
       "      <td>0.242321</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.48431</td>\n",
       "      <td>0.798813</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E-35921</th>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.613005</td>\n",
       "      <td>0.556224</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.783844</td>\n",
       "      <td>0.319924</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.578408</td>\n",
       "      <td>0.832003</td>\n",
       "      <td>0.607354</td>\n",
       "      <td>0.649126</td>\n",
       "      <td>0.678144</td>\n",
       "      <td>0.244074</td>\n",
       "      <td>0.537398</td>\n",
       "      <td>0.542829</td>\n",
       "      <td>0.717201</td>\n",
       "      <td>0.597468</td>\n",
       "      <td>0.641526</td>\n",
       "      <td>0.217876</td>\n",
       "      <td>0.560113</td>\n",
       "      <td>0.673866</td>\n",
       "      <td>0.858511</td>\n",
       "      <td>0.280247</td>\n",
       "      <td>0.524941</td>\n",
       "      <td>0.257035</td>\n",
       "      <td>0.321667</td>\n",
       "      <td>0.747876</td>\n",
       "      <td>0.765465</td>\n",
       "      <td>0.649659</td>\n",
       "      <td>0.68666</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.761518</td>\n",
       "      <td>0.238011</td>\n",
       "      <td>0.339658</td>\n",
       "      <td>0.827053</td>\n",
       "      <td>0.416164</td>\n",
       "      <td>0.607037</td>\n",
       "      <td>0.384237</td>\n",
       "      <td>0.762382</td>\n",
       "      <td>0.538047</td>\n",
       "      <td>0.631182</td>\n",
       "      <td>0.656812</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.621555</td>\n",
       "      <td>0.400266</td>\n",
       "      <td>0.395117</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.502167</td>\n",
       "      <td>0.649828</td>\n",
       "      <td>0.542929</td>\n",
       "      <td>0.224756</td>\n",
       "      <td>0.319087</td>\n",
       "      <td>0.52821</td>\n",
       "      <td>0.728187</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.81889</td>\n",
       "      <td>0.364122</td>\n",
       "      <td>0.242321</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.48431</td>\n",
       "      <td>0.798813</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PP1       PP2       PP3       KF1       KF2       KF3       KF4       KF5       KF7       KF8        Z1        Z2        Z3        Z4        Z5        F2        F3        F4        F5        F6        T1        T2        T3        T4        T5     VHSE1     VHSE2     VHSE3     VHSE4    VHSE5     VHSE6     VHSE7     VHSE8   ProtFP1   ProtFP2   ProtFP3   ProtFP4   ProtFP5   ProtFP6   ProtFP7   ProtFP8       ST1       ST2       ST3       ST4       ST5       ST6       ST7       ST8   BLOSUM1   BLOSUM2   BLOSUM3   BLOSUM4  BLOSUM5   BLOSUM6   BLOSUM7  BLOSUM8   BLOSUM9  BLOSUM10   MSWHIM1  MSWHIM2   MSWHIM3     Class\n",
       "Epitope                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "E-10004  0.6574  0.613005  0.556224  0.411765  0.783844  0.319924  0.742857  0.578408  0.832003  0.607354  0.649126  0.678144  0.244074  0.537398  0.542829  0.717201  0.597468  0.641526  0.217876  0.560113  0.673866  0.858511  0.280247  0.524941  0.257035  0.321667  0.747876  0.765465  0.649659  0.68666  0.670588  0.761518  0.238011  0.339658  0.827053  0.416164  0.607037  0.384237  0.762382  0.538047  0.631182  0.656812  0.734884  0.621555  0.400266  0.395117  0.849941  0.457679  0.502167  0.649828  0.542929  0.224756  0.319087  0.52821  0.728187  0.423611  0.81889  0.364122  0.242321  0.562044  0.48431  0.798813  Negative\n",
       "E-31523  0.6574  0.613005  0.556224  0.411765  0.783844  0.319924  0.742857  0.578408  0.832003  0.607354  0.649126  0.678144  0.244074  0.537398  0.542829  0.717201  0.597468  0.641526  0.217876  0.560113  0.673866  0.858511  0.280247  0.524941  0.257035  0.321667  0.747876  0.765465  0.649659  0.68666  0.670588  0.761518  0.238011  0.339658  0.827053  0.416164  0.607037  0.384237  0.762382  0.538047  0.631182  0.656812  0.734884  0.621555  0.400266  0.395117  0.849941  0.457679  0.502167  0.649828  0.542929  0.224756  0.319087  0.52821  0.728187  0.423611  0.81889  0.364122  0.242321  0.562044  0.48431  0.798813  Negative\n",
       "E-31793  0.6574  0.613005  0.556224  0.411765  0.783844  0.319924  0.742857  0.578408  0.832003  0.607354  0.649126  0.678144  0.244074  0.537398  0.542829  0.717201  0.597468  0.641526  0.217876  0.560113  0.673866  0.858511  0.280247  0.524941  0.257035  0.321667  0.747876  0.765465  0.649659  0.68666  0.670588  0.761518  0.238011  0.339658  0.827053  0.416164  0.607037  0.384237  0.762382  0.538047  0.631182  0.656812  0.734884  0.621555  0.400266  0.395117  0.849941  0.457679  0.502167  0.649828  0.542929  0.224756  0.319087  0.52821  0.728187  0.423611  0.81889  0.364122  0.242321  0.562044  0.48431  0.798813  Negative\n",
       "E-35921  0.6574  0.613005  0.556224  0.411765  0.783844  0.319924  0.742857  0.578408  0.832003  0.607354  0.649126  0.678144  0.244074  0.537398  0.542829  0.717201  0.597468  0.641526  0.217876  0.560113  0.673866  0.858511  0.280247  0.524941  0.257035  0.321667  0.747876  0.765465  0.649659  0.68666  0.670588  0.761518  0.238011  0.339658  0.827053  0.416164  0.607037  0.384237  0.762382  0.538047  0.631182  0.656812  0.734884  0.621555  0.400266  0.395117  0.849941  0.457679  0.502167  0.649828  0.542929  0.224756  0.319087  0.52821  0.728187  0.423611  0.81889  0.364122  0.242321  0.562044  0.48431  0.798813  Negative"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[cols])\n",
    "data[cols] = scaler.transform(data[cols])\n",
    "data.loc[\"LDRLFNKKKELGQDK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create testing and training data</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Test and training data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(columns='Class')\n",
    "y_train = data[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create k folds</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=True, random_state=42 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "state = 42\n",
    "folds = 8\n",
    "kf = KFold(folds, True, state).split(X_train)\n",
    "split = []\n",
    "for x in range(folds):\n",
    "    split.append(next(kf, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>K folds on training data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X,y):\n",
    "\n",
    "    global X_tn\n",
    "    global X_tt\n",
    "    global y_tn\n",
    "    global y_tt\n",
    "\n",
    "    X_tn = []\n",
    "    X_tt = []\n",
    "    y_tn = []\n",
    "    y_tt = []\n",
    "    \n",
    "    for x in range(folds):\n",
    "        X_tn.append(X.iloc[split[x][0]])\n",
    "        X_tt.append(X.iloc[split[x][1]])\n",
    "        y_tn.append(y.iloc[split[x][0]])\n",
    "        y_tt.append(y.iloc[split[x][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Classifiers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers ={\n",
    "    \"Naive Bayes\" : GaussianNB(),\n",
    "    \"Decision Tree\" : DecisionTreeClassifier(random_state=state),\n",
    "    \"MLP Classifier\" : MLPClassifier(max_iter=1000, random_state=state),\n",
    "    \"Logistic Regression\" : LogisticRegression(max_iter=1000, random_state=state),\n",
    "    \"K Neighbors Classifier\" : KNeighborsClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train model and retrieve results</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(model, s = None, d= True, i = 0):\n",
    "    if d==True:\n",
    "        print(\"Training\",model)\n",
    "    t_start = time.time()\n",
    "    best = 0\n",
    "    y_pred_best = []\n",
    "    \n",
    "    if s == None:\n",
    "        for x in range(folds):\n",
    "\n",
    "            MLPC_model = classifiers[model]\n",
    "            MLPC_model.fit(X_tn[x], y_tn[x])\n",
    "            y_pred = MLPC_model.predict(X_tt[x])\n",
    "            \n",
    "            f1_scr = f1_score(y_tt[x], y_pred, pos_label=\"Positive\")\n",
    "\n",
    "            if best<f1_scr:\n",
    "                fold = x\n",
    "                best = f1_scr\n",
    "                y_pred_best = y_pred\n",
    "\n",
    "        best_fold.append(fold)\n",
    "        print(y_tt[fold])\n",
    "        print(y_pred_best)\n",
    "        f1[i].append(f1_score(y_tt[fold],y_pred_best, pos_label=\"Positive\"))\n",
    "        acc[i].append(accuracy_score(y_tt[fold],y_pred_best))\n",
    "        \n",
    "    else:\n",
    "        MLPC_model = classifiers[model]\n",
    "        MLPC_model.fit(X_tn[s], y_tn[s])\n",
    "\n",
    "        y_pred_best = MLPC_model.predict(X_tt[s])\n",
    "        fold = s\n",
    "        f1[i].append(f1_score(y_tt[fold],y_pred_best, pos_label=\"Positive\"))\n",
    "        acc[i].append(accuracy_score(y_tt[fold],y_pred_best))\n",
    "    \n",
    "    if d ==True:\n",
    "        print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
    "        print(\"Best fold:\",fold+1)\n",
    "        print(classification_report(y_tt[fold], y_pred_best))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_tt[fold], y_pred_best).ravel()\n",
    "        print(\"True Negatives:\",tn)\n",
    "        print(\"False Negatives\",fn)\n",
    "        print(\"True Positives\",tp) \n",
    "        print(\"False Positive\",fp)\n",
    "        print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Benchmark models</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes\n",
      "ID               Epitope\n",
      "LKSYENFLPEAKVTT  E-2675     Negative\n",
      "PLAGVYRSLKKQIEK  E-34796    Negative\n",
      "AKLNDVCANDYCQIP  E-32041    Negative\n",
      "QIGSHFHFFEVNRCL  E-16104    Negative\n",
      "KNIFTFNLNLNDILN  E-17195    Negative\n",
      "                              ...   \n",
      "YLFYYYLKDIKSMLS  E-36041    Negative\n",
      "QTAQAAPVQEGVQQE  E-12128    Negative\n",
      "NDIEKKICKMEKCSS  E-31184    Negative\n",
      "INDFILILNDKKFME  E-36608    Negative\n",
      "DIIHHAAGLGGIGAI  E-26513    Negative\n",
      "Name: Class, Length: 1492, dtype: object\n",
      "['Negative' 'Negative' 'Negative' ... 'Negative' 'Negative' 'Positive']\n",
      "Time Taken: 0.25\n",
      "Best fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.84      0.88      1283\n",
      "    Positive       0.34      0.49      0.40       209\n",
      "\n",
      "    accuracy                           0.79      1492\n",
      "   macro avg       0.62      0.67      0.64      1492\n",
      "weighted avg       0.83      0.79      0.81      1492\n",
      "\n",
      "True Negatives: 1083\n",
      "False Negatives 107\n",
      "True Positives 102\n",
      "False Positive 200\n",
      "-------------------------------------------\n",
      "Training Decision Tree\n",
      "ID               Epitope\n",
      "DRGYISQYFATNREK  E-15456    Positive\n",
      "ERKIFINNIKKQIDL  E-30591    Negative\n",
      "RIFGFNALVDRQADN  E-19589    Negative\n",
      "GELAKKRKEKGIKLN  E-2223     Negative\n",
      "EQGMMLAEQFKQKAL  E-25940    Negative\n",
      "                              ...   \n",
      "KKNENIKELLDKINE  E-13150    Negative\n",
      "LDKINEIKNPPPANS  E-37164    Negative\n",
      "QTNSSTKFLGKNKLA  E-16624    Negative\n",
      "YEDIVLKSHMNRESD  E-11361    Negative\n",
      "LMVCHHLDKSIKEDV  E-42917    Negative\n",
      "Name: Class, Length: 1492, dtype: object\n",
      "['Negative' 'Negative' 'Negative' ... 'Negative' 'Negative' 'Negative']\n",
      "Time Taken: 6.43\n",
      "Best fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.94      0.94      1294\n",
      "    Positive       0.58      0.54      0.56       198\n",
      "\n",
      "    accuracy                           0.89      1492\n",
      "   macro avg       0.76      0.74      0.75      1492\n",
      "weighted avg       0.88      0.89      0.89      1492\n",
      "\n",
      "True Negatives: 1218\n",
      "False Negatives 92\n",
      "True Positives 106\n",
      "False Positive 76\n",
      "-------------------------------------------\n",
      "Training MLP Classifier\n",
      "ID               Epitope\n",
      "VSKEIPYEEYLQEIG  E-23146    Negative\n",
      "GQGISAWSKTFCALF  E-20713    Negative\n",
      "DKIDTQRRTYELNTL  E-31206    Negative\n",
      "GGIEGEIVDAFRYGY  E-12155    Negative\n",
      "FSPGHVWESANPFCG  E-14116    Negative\n",
      "                              ...   \n",
      "DHRPGGGLCHAFYQR  E-35055    Negative\n",
      "TEGAGGGHAPDIIKV  E-19873    Negative\n",
      "EKSGRDYIPGRQLEF  E-10904    Negative\n",
      "KYKLKLDRLFNKKKE  E-35281    Negative\n",
      "TKEYEDIVLKSHMNR  E-39984    Positive\n",
      "Name: Class, Length: 1492, dtype: object\n",
      "['Negative' 'Negative' 'Negative' ... 'Negative' 'Negative' 'Negative']\n",
      "Time Taken: 101.02\n",
      "Best fold: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.97      0.94      1291\n",
      "    Positive       0.68      0.39      0.50       201\n",
      "\n",
      "    accuracy                           0.89      1492\n",
      "   macro avg       0.80      0.68      0.72      1492\n",
      "weighted avg       0.88      0.89      0.88      1492\n",
      "\n",
      "True Negatives: 1254\n",
      "False Negatives 122\n",
      "True Positives 79\n",
      "False Positive 37\n",
      "-------------------------------------------\n",
      "Training Logistic Regression\n",
      "ID               Epitope\n",
      "ALRKNLATAQSLEKE  E-34980    Negative\n",
      "NANANNAVKNNNNEE  E-13438    Positive\n",
      "GDSEIAKTTLLKILA  E-10103    Negative\n",
      "KNGIEINCCTTDRCN  E-27596    Negative\n",
      "PDYNPLLVETWKKPD  E-10932    Positive\n",
      "                              ...   \n",
      "VLVRMKELAVQSGNG  E-35014    Negative\n",
      "DHPLVIERVRAIGCH  E-24475    Negative\n",
      "RVRNYLFTIKELKYP  E-35999    Negative\n",
      "HVTSTLTSLFRPGAS  E-40172    Negative\n",
      "MGVIGFSFFVKDWSE  E-22998    Negative\n",
      "Name: Class, Length: 1492, dtype: object\n",
      "['Negative' 'Negative' 'Negative' ... 'Negative' 'Negative' 'Negative']\n",
      "Time Taken: 1.63\n",
      "Best fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.99      0.94      1318\n",
      "    Positive       0.57      0.11      0.19       174\n",
      "\n",
      "    accuracy                           0.89      1492\n",
      "   macro avg       0.73      0.55      0.57      1492\n",
      "weighted avg       0.86      0.89      0.85      1492\n",
      "\n",
      "True Negatives: 1303\n",
      "False Negatives 154\n",
      "True Positives 20\n",
      "False Positive 15\n",
      "-------------------------------------------\n",
      "Training K Neighbors Classifier\n",
      "ID               Epitope\n",
      "QLQNYDEEDDSLVVL  E-11303    Negative\n",
      "GKIKVYVGNYDFWYQ  E-21549    Positive\n",
      "NELKSCDPLDLLFNI  E-13140    Negative\n",
      "FELYQKEMIYYLHKL  E-41799    Negative\n",
      "MEEARAGKKTAAELM  E-1576     Negative\n",
      "                              ...   \n",
      "YIMKESEREHLVIKK  E-40807    Negative\n",
      "TLTKTSLEEIALHSS  E-33770    Positive\n",
      "SVLEKRIDTLKKNEN  E-12864    Negative\n",
      "EEEEQLISQASSKQA  E-35428    Negative\n",
      "AGRTMHTFHTEGAGG  E-22216    Negative\n",
      "Name: Class, Length: 1492, dtype: object\n",
      "['Negative' 'Positive' 'Negative' ... 'Negative' 'Negative' 'Negative']\n",
      "Time Taken: 2.51\n",
      "Best fold: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.97      0.95      1278\n",
      "    Positive       0.74      0.52      0.61       214\n",
      "\n",
      "    accuracy                           0.90      1492\n",
      "   macro avg       0.83      0.74      0.78      1492\n",
      "weighted avg       0.90      0.90      0.90      1492\n",
      "\n",
      "True Negatives: 1238\n",
      "False Negatives 103\n",
      "True Positives 111\n",
      "False Positive 40\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "split_data(X_train, y_train)\n",
    "f1 = [[]]\n",
    "acc =[[]]\n",
    "best_fold = []\n",
    "\n",
    "for y in enumerate(classifiers):\n",
    "    model_results(y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Selection via:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Variance</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F5          0.008889\n",
       "Z5          0.009400\n",
       "VHSE8       0.010012\n",
       "BLOSUM6     0.011907\n",
       "BLOSUM5     0.012038\n",
       "F4          0.012626\n",
       "Z3          0.012699\n",
       "MSWHIM2     0.012900\n",
       "KF8         0.013066\n",
       "Z1          0.013212\n",
       "ST4         0.013581\n",
       "Z4          0.013766\n",
       "ProtFP5     0.013811\n",
       "ProtFP6     0.013888\n",
       "BLOSUM1     0.013982\n",
       "ProtFP1     0.014034\n",
       "ST7         0.014212\n",
       "VHSE1       0.014795\n",
       "ST5         0.015080\n",
       "ProtFP4     0.015188\n",
       "VHSE4       0.015615\n",
       "VHSE5       0.016037\n",
       "ProtFP8     0.016600\n",
       "ProtFP3     0.016801\n",
       "VHSE7       0.016864\n",
       "BLOSUM2     0.016947\n",
       "PP1         0.016975\n",
       "F3          0.017308\n",
       "VHSE6       0.017749\n",
       "T2          0.017770\n",
       "Z2          0.017788\n",
       "PP2         0.017838\n",
       "KF1         0.017963\n",
       "F6          0.018365\n",
       "KF4         0.018436\n",
       "T1          0.018757\n",
       "MSWHIM1     0.018990\n",
       "BLOSUM7     0.019114\n",
       "T4          0.019148\n",
       "ST1         0.019235\n",
       "ProtFP7     0.019245\n",
       "BLOSUM8     0.019249\n",
       "BLOSUM9     0.019448\n",
       "ST8         0.019746\n",
       "VHSE2       0.019760\n",
       "PP3         0.019805\n",
       "KF5         0.019925\n",
       "ST2         0.020076\n",
       "VHSE3       0.020791\n",
       "F2          0.020859\n",
       "T5          0.021921\n",
       "KF7         0.022040\n",
       "BLOSUM10    0.022257\n",
       "KF2         0.022305\n",
       "ST3         0.022647\n",
       "ProtFP2     0.022664\n",
       "T3          0.022963\n",
       "BLOSUM4     0.023243\n",
       "KF3         0.023555\n",
       "BLOSUM3     0.024297\n",
       "MSWHIM3     0.025897\n",
       "ST6         0.026056\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.var().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 14\n",
      "f1 score: [0.20612813370473537, 0.5189189189189188, 0.38235294117647056, 0.11282051282051284, 0.5698324022346368]\n",
      "acc: [0.8089812332439679, 0.8806970509383378, 0.8873994638069705, 0.8840482573726541, 0.8967828418230563]\n"
     ]
    }
   ],
   "source": [
    "split_data(X_train, y_train)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "select = VarianceThreshold(threshold=(0.02))\n",
    "select.fit_transform(data.drop(columns='Class'))\n",
    "\n",
    "cols = []\n",
    "for x in enumerate(select.get_support(indices=True)):\n",
    "    cols.append(data.columns[x[1]])\n",
    "\n",
    "print(\"Features:\",len(cols))\n",
    "\n",
    "f1 = [[]]\n",
    "acc = [[]]\n",
    "\n",
    "X_train_1 = X_train[cols].copy()\n",
    "\n",
    "split_data(X_train_1, y_train)\n",
    "\n",
    "index = 0\n",
    "for i in enumerate(classifiers):\n",
    "    model_results(i[1], s = best_fold[index], d=False)\n",
    "    index = index+1\n",
    "\n",
    "print(\"f1 score:\",f1[0])\n",
    "print(\"acc:\",acc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Univariate Feature Selection</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=wjKvyk8xStg\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl = f_classif(X_train, y_train)\n",
    "cl = pd.Series(cl[0])\n",
    "cl.index = X_train.columns\n",
    "cl.sort_values(ascending=False, inplace = True)\n",
    "\n",
    "plt.title('Metric for association: f_classif')\n",
    "cl.plot.bar(figsize = (16,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Remove coorelations</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 39\n",
      "f1 score: [0.39913232104121477, 0.5531914893617021, 0.46735395189003437, 0.17647058823529413, 0.6186666666666667]\n"
     ]
    }
   ],
   "source": [
    "#Drop one of high correlated pair\n",
    "#Multicollinearity\n",
    "pos_data = X_train.corr().abs()\n",
    "unstack_data = pos_data.unstack()\n",
    "corr_data = pd.DataFrame(unstack_data)\n",
    "\n",
    "corrs = []\n",
    "for x in range(62**2):\n",
    "    corrs.append([corr_data.index[x],corr_data.values[x][0]])\n",
    "    \n",
    "corrs = sorted(corrs, key=lambda x: -x[1])\n",
    "corrs = corrs[62:-1: 2]\n",
    "\n",
    "drop_features = []\n",
    "for x in range(len(corrs)):\n",
    "    if corrs[x][1] >= 0.8:\n",
    "        a = corrs[x][0][0]\n",
    "        b = corrs[x][0][1]\n",
    "        if a not in drop_features or b not in drop_features:\n",
    "            if cl[a] >= cl[b]:\n",
    "                c = 1\n",
    "            else:\n",
    "                c = 0\n",
    "            drop_features.append(corrs[x][0][c])\n",
    "        \n",
    "drop_features = list(dict.fromkeys(drop_features))\n",
    "X_train_2 = X_train.drop(columns=drop_features)\n",
    "print(\"Features:\",X_train_2.shape[1])\n",
    "\n",
    "split_data(X_train_2, y_train)\n",
    "\n",
    "f1 = [[]]\n",
    "index = 0\n",
    "for i in enumerate(classifiers):\n",
    "    model_results(i[1], s = best_fold[index], d=False)\n",
    "    index = index+1\n",
    "\n",
    "print(\"f1 score:\",f1[0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<h4>f_classif W/O correlation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .............\n",
      "0.8525469168900804\n",
      "0.8659517426273459\n",
      "0.8652815013404825\n",
      "0.8840482573726541\n",
      "0.8532171581769437\n",
      "2 .............\n",
      "0.8545576407506702\n",
      "0.8693029490616622\n",
      "0.8652815013404825\n",
      "0.8840482573726541\n",
      "0.8592493297587132\n",
      "3 .............\n",
      "0.8558981233243967\n",
      "0.863941018766756\n",
      "0.868632707774799\n",
      "0.8833780160857909\n",
      "0.8605898123324397\n",
      "4 .............\n",
      "0.8532171581769437\n",
      "0.878686327077748\n",
      "0.8693029490616622\n",
      "0.8847184986595175\n",
      "0.868632707774799\n",
      "5 .............\n",
      "0.8525469168900804\n",
      "0.886058981233244\n",
      "0.8679624664879356\n",
      "0.8853887399463807\n",
      "0.8646112600536193\n",
      "6 .............\n",
      "0.8445040214477212\n",
      "0.8806970509383378\n",
      "0.8652815013404825\n",
      "0.8840482573726541\n",
      "0.878686327077748\n",
      "7 .............\n",
      "0.8424932975871313\n",
      "0.886058981233244\n",
      "0.8739946380697051\n",
      "0.8847184986595175\n",
      "0.8820375335120644\n",
      "8 .............\n",
      "0.8431635388739946\n",
      "0.8739946380697051\n",
      "0.8753351206434317\n",
      "0.8853887399463807\n",
      "0.8800268096514745\n",
      "9 .............\n",
      "0.839142091152815\n",
      "0.8699731903485255\n",
      "0.8800268096514745\n",
      "0.8833780160857909\n",
      "0.8853887399463807\n",
      "10 .............\n",
      "0.8378016085790885\n",
      "0.8739946380697051\n",
      "0.8766756032171582\n",
      "0.886058981233244\n",
      "0.8827077747989276\n",
      "11 .............\n",
      "0.8324396782841823\n",
      "0.8827077747989276\n",
      "0.8793565683646113\n",
      "0.886058981233244\n",
      "0.8920911528150134\n",
      "12 .............\n",
      "0.8331099195710456\n",
      "0.8840482573726541\n",
      "0.8760053619302949\n",
      "0.8853887399463807\n",
      "0.8934316353887399\n",
      "13 .............\n",
      "0.8304289544235925\n",
      "0.881367292225201\n",
      "0.8780160857908847\n",
      "0.8867292225201072\n",
      "0.8894101876675603\n",
      "14 .............\n",
      "0.8310991957104558\n",
      "0.8780160857908847\n",
      "0.886058981233244\n",
      "0.886058981233244\n",
      "0.8941018766756033\n",
      "15 .............\n",
      "0.8250670241286864\n",
      "0.8880697050938338\n",
      "0.878686327077748\n",
      "0.8867292225201072\n",
      "0.8941018766756033\n",
      "1 .............\n",
      "0.10569105691056911\n",
      "0.20000000000000004\n",
      "0.056338028169014086\n",
      "0.011428571428571429\n",
      "0.21505376344086022\n",
      "2 .............\n",
      "0.17490494296577946\n",
      "0.46280991735537186\n",
      "0.056338028169014086\n",
      "0.011428571428571429\n",
      "0.3181818181818182\n",
      "3 .............\n",
      "0.22939068100358423\n",
      "0.4615384615384615\n",
      "0.11711711711711711\n",
      "0.011363636363636362\n",
      "0.36969696969696964\n",
      "4 .............\n",
      "0.22614840989399293\n",
      "0.4901408450704226\n",
      "0.14847161572052403\n",
      "0.06521739130434784\n",
      "0.3950617283950617\n",
      "5 .............\n",
      "0.2567567567567568\n",
      "0.532967032967033\n",
      "0.1471861471861472\n",
      "0.06557377049180328\n",
      "0.39520958083832336\n",
      "6 .............\n",
      "0.25641025641025644\n",
      "0.5265957446808511\n",
      "0.15189873417721517\n",
      "0.044198895027624314\n",
      "0.47230320699708445\n",
      "7 .............\n",
      "0.31085043988269795\n",
      "0.532967032967033\n",
      "0.21008403361344538\n",
      "0.05494505494505494\n",
      "0.4942528735632183\n",
      "8 .............\n",
      "0.3389830508474576\n",
      "0.4946236559139785\n",
      "0.23140495867768596\n",
      "0.07567567567567568\n",
      "0.4929178470254958\n",
      "9 .............\n",
      "0.3478260869565218\n",
      "0.4867724867724868\n",
      "0.31417624521072796\n",
      "0.07446808510638298\n",
      "0.5155807365439093\n",
      "10 .............\n",
      "0.3631578947368421\n",
      "0.48633879781420764\n",
      "0.25806451612903225\n",
      "0.09574468085106383\n",
      "0.5014245014245013\n",
      "11 .............\n",
      "0.3523316062176166\n",
      "0.5179063360881543\n",
      "0.2682926829268293\n",
      "0.11458333333333336\n",
      "0.5413105413105413\n",
      "12 .............\n",
      "0.35658914728682173\n",
      "0.5336927223719676\n",
      "0.23868312757201648\n",
      "0.10471204188481674\n",
      "0.5643835616438357\n",
      "13 .............\n",
      "0.3529411764705882\n",
      "0.5177111716621253\n",
      "0.272\n",
      "0.13333333333333336\n",
      "0.5429362880886426\n",
      "14 .............\n",
      "0.37623762376237624\n",
      "0.5185185185185185\n",
      "0.37037037037037035\n",
      "0.12371134020618556\n",
      "0.56353591160221\n",
      "15 .............\n",
      "0.3741007194244605\n",
      "0.5449591280653951\n",
      "0.27888446215139445\n",
      "0.13333333333333336\n",
      "0.56353591160221\n"
     ]
    }
   ],
   "source": [
    "t = f_classif\n",
    "num = 16\n",
    "\n",
    "split_data(X_train, y_train)\n",
    "select = SelectKBest(t, k=num)\n",
    "select.fit_transform(X_train, y_train)\n",
    "\n",
    "cols = []\n",
    "for x in enumerate(select.get_support(indices=True)):\n",
    "    cols.append(X_train.columns[x[1]])\n",
    "\n",
    "ordered = [x for _,x in sorted(zip(select.scores_,cols))]\n",
    "ordered.reverse()\n",
    "\n",
    "f1 = []\n",
    "acc =[]\n",
    "for x in range(1,num):\n",
    "    f1.append([])\n",
    "    acc.append([])\n",
    "    use = ordered[0:x]\n",
    "    X_train_new = X_train[use].copy()\n",
    "    index = 0\n",
    "    \n",
    "    split_data(X_train_new, y_train)\n",
    "    for i in enumerate(classifiers):\n",
    "        model_results(i[1], s = best_fold[index], d=False, i=(x-1))\n",
    "        index = index+1\n",
    "\n",
    "for x in range(len(acc)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(acc[x])):\n",
    "        print(acc[x][y])\n",
    "for x in range(len(f1)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(f1[x])):\n",
    "        print(f1[x][y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>f_classif W correlation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .............\n",
      "0.8599195710455764\n",
      "0.8699731903485255\n",
      "0.8652815013404825\n",
      "0.8833780160857909\n",
      "0.8532171581769437\n",
      "2 .............\n",
      "0.8599195710455764\n",
      "0.8652815013404825\n",
      "0.8652815013404825\n",
      "0.8833780160857909\n",
      "0.8565683646112601\n",
      "3 .............\n",
      "0.8679624664879356\n",
      "0.8746648793565683\n",
      "0.8719839142091153\n",
      "0.8820375335120644\n",
      "0.8666219839142091\n",
      "4 .............\n",
      "0.8605898123324397\n",
      "0.8833780160857909\n",
      "0.8719839142091153\n",
      "0.881367292225201\n",
      "0.868632707774799\n",
      "5 .............\n",
      "0.8652815013404825\n",
      "0.8880697050938338\n",
      "0.8753351206434317\n",
      "0.8847184986595175\n",
      "0.8766756032171582\n",
      "6 .............\n",
      "0.863941018766756\n",
      "0.8894101876675603\n",
      "0.8726541554959786\n",
      "0.8847184986595175\n",
      "0.8766756032171582\n",
      "7 .............\n",
      "0.8699731903485255\n",
      "0.881367292225201\n",
      "0.8773458445040214\n",
      "0.8833780160857909\n",
      "0.8827077747989276\n",
      "8 .............\n",
      "0.8558981233243967\n",
      "0.8847184986595175\n",
      "0.8820375335120644\n",
      "0.8853887399463807\n",
      "0.8981233243967829\n",
      "9 .............\n",
      "0.8478552278820375\n",
      "0.8760053619302949\n",
      "0.8800268096514745\n",
      "0.8853887399463807\n",
      "0.8900804289544236\n",
      "10 .............\n",
      "0.8411528150134048\n",
      "0.8867292225201072\n",
      "0.881367292225201\n",
      "0.8853887399463807\n",
      "0.8907506702412868\n",
      "11 .............\n",
      "0.8331099195710456\n",
      "0.878686327077748\n",
      "0.8827077747989276\n",
      "0.8867292225201072\n",
      "0.8900804289544236\n",
      "12 .............\n",
      "0.8364611260053619\n",
      "0.8773458445040214\n",
      "0.8820375335120644\n",
      "0.8853887399463807\n",
      "0.8947721179624665\n",
      "13 .............\n",
      "0.8378016085790885\n",
      "0.8880697050938338\n",
      "0.8833780160857909\n",
      "0.8887399463806971\n",
      "0.8941018766756033\n",
      "14 .............\n",
      "0.8411528150134048\n",
      "0.878686327077748\n",
      "0.878686327077748\n",
      "0.8880697050938338\n",
      "0.9021447721179625\n",
      "15 .............\n",
      "0.8424932975871313\n",
      "0.8820375335120644\n",
      "0.8853887399463807\n",
      "0.8853887399463807\n",
      "0.9021447721179625\n",
      "1 .............\n",
      "0.0\n",
      "0.24806201550387597\n",
      "0.0\n",
      "0.0\n",
      "0.19188191881918817\n",
      "2 .............\n",
      "0.0\n",
      "0.45822102425876005\n",
      "0.0\n",
      "0.0\n",
      "0.2913907284768212\n",
      "3 .............\n",
      "0.18257261410788383\n",
      "0.49865951742627346\n",
      "0.1278538812785388\n",
      "0.0\n",
      "0.3642172523961661\n",
      "4 .............\n",
      "0.2517985611510792\n",
      "0.5193370165745855\n",
      "0.18025751072961374\n",
      "0.0\n",
      "0.3987730061349693\n",
      "5 .............\n",
      "0.2690909090909091\n",
      "0.5498652291105122\n",
      "0.1842105263157895\n",
      "0.044444444444444446\n",
      "0.4320987654320987\n",
      "6 .............\n",
      "0.311864406779661\n",
      "0.5576407506702413\n",
      "0.22764227642276422\n",
      "0.044444444444444446\n",
      "0.4556213017751479\n",
      "7 .............\n",
      "0.3660130718954248\n",
      "0.5378590078328982\n",
      "0.23430962343096234\n",
      "0.11224489795918369\n",
      "0.4868035190615836\n",
      "8 .............\n",
      "0.3582089552238805\n",
      "0.5473684210526316\n",
      "0.3282442748091603\n",
      "0.12307692307692308\n",
      "0.5632183908045977\n",
      "9 .............\n",
      "0.3495702005730659\n",
      "0.5040214477211796\n",
      "0.2924901185770751\n",
      "0.10471204188481674\n",
      "0.5444444444444444\n",
      "10 .............\n",
      "0.3398328690807799\n",
      "0.5517241379310346\n",
      "0.3218390804597701\n",
      "0.11398963730569951\n",
      "0.5408450704225352\n",
      "11 .............\n",
      "0.3324396782841823\n",
      "0.527415143603133\n",
      "0.31906614785992216\n",
      "0.12435233160621761\n",
      "0.5444444444444444\n",
      "12 .............\n",
      "0.36125654450261785\n",
      "0.5171503957783641\n",
      "0.3282442748091603\n",
      "0.1319796954314721\n",
      "0.5650969529085872\n",
      "13 .............\n",
      "0.38578680203045684\n",
      "0.5546666666666666\n",
      "0.3255813953488372\n",
      "0.1782178217821782\n",
      "0.572972972972973\n",
      "14 .............\n",
      "0.41769041769041765\n",
      "0.5173333333333333\n",
      "0.27888446215139445\n",
      "0.1691542288557214\n",
      "0.5966850828729281\n",
      "15 .............\n",
      "0.4226044226044226\n",
      "0.5392670157068064\n",
      "0.36900369003690037\n",
      "0.1319796954314721\n",
      "0.5989010989010989\n"
     ]
    }
   ],
   "source": [
    "t = f_classif\n",
    "num = 16\n",
    "\n",
    "split_data(X_train_2, y_train)\n",
    "select = SelectKBest(t, k=num)\n",
    "select.fit_transform(X_train_2, y_train)\n",
    "\n",
    "cols = []\n",
    "for x in enumerate(select.get_support(indices=True)):\n",
    "    cols.append(X_train_2.columns[x[1]])\n",
    "\n",
    "ordered = [x for _,x in sorted(zip(select.scores_,cols))]\n",
    "ordered.reverse()\n",
    "\n",
    "f1 = []\n",
    "acc =[]\n",
    "for x in range(1,num):\n",
    "    f1.append([])\n",
    "    acc.append([])\n",
    "    use = ordered[0:x]\n",
    "    X_train_new = X_train_2[use].copy()\n",
    "    index = 0\n",
    "    \n",
    "    if x ==15:\n",
    "        selected_model_1 = X_train_new.copy()\n",
    "    \n",
    "    split_data(X_train_new, y_train)\n",
    "    for i in enumerate(classifiers):\n",
    "        model_results(i[1], s = best_fold[index], d=False, i=(x-1))\n",
    "        index = index+1\n",
    "        \n",
    "for x in range(len(acc)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(acc[x])):\n",
    "        print(acc[x][y])\n",
    "for x in range(len(f1)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(f1[x])):\n",
    "        print(f1[x][y])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl = chi2(X_train, y_train)\n",
    "cl = pd.Series(cl[0])\n",
    "cl.index = X_train.columns\n",
    "cl.sort_values(ascending=False, inplace = True)\n",
    "\n",
    "plt.title('Metric for association: chi2')\n",
    "cl.plot.bar(figsize = (16,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 39\n",
      "f1 score: [0.40170940170940167, 0.5454545454545455, 0.4717607973421926, 0.16748768472906403, 0.6253369272237196]\n"
     ]
    }
   ],
   "source": [
    "#Drop one of high correlated pair\n",
    "#Multicollinearity\n",
    "pos_data = X_train.corr().abs()\n",
    "unstack_data = pos_data.unstack()\n",
    "corr_data = pd.DataFrame(unstack_data)\n",
    "\n",
    "corrs = []\n",
    "for x in range(62**2):\n",
    "    corrs.append([corr_data.index[x],corr_data.values[x][0]])\n",
    "    \n",
    "corrs = sorted(corrs, key=lambda x: -x[1])\n",
    "corrs = corrs[62:-1: 2]\n",
    "\n",
    "drop_features = []\n",
    "for x in range(len(corrs)):\n",
    "    if corrs[x][1] >= 0.8:\n",
    "        a = corrs[x][0][0]\n",
    "        b = corrs[x][0][1]\n",
    "        if a not in drop_features or b not in drop_features:\n",
    "            if cl[a] >= cl[b]:\n",
    "                c = 1\n",
    "            else:\n",
    "                c = 0\n",
    "            drop_features.append(corrs[x][0][c])\n",
    "        \n",
    "drop_features = list(dict.fromkeys(drop_features))\n",
    "X_train_2 = X_train.drop(columns=drop_features)\n",
    "print(\"Features:\",X_train_2.shape[1])\n",
    "\n",
    "split_data(X_train_2, y_train)\n",
    "\n",
    "f1 = [[]]\n",
    "index = 0\n",
    "for i in enumerate(classifiers):\n",
    "    model_results(i[1], s = best_fold[index], d=False)\n",
    "    index = index+1\n",
    "\n",
    "print(\"f1 score:\",f1[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .............\n",
      "0.8619302949061662\n",
      "0.8766756032171582\n",
      "0.8652815013404825\n",
      "0.8833780160857909\n",
      "0.8545576407506702\n",
      "2 .............\n",
      "0.8612600536193029\n",
      "0.8739946380697051\n",
      "0.8652815013404825\n",
      "0.8847184986595175\n",
      "0.8545576407506702\n",
      "3 .............\n",
      "0.8626005361930295\n",
      "0.8706434316353887\n",
      "0.863941018766756\n",
      "0.8867292225201072\n",
      "0.8679624664879356\n",
      "4 .............\n",
      "0.8626005361930295\n",
      "0.881367292225201\n",
      "0.8672922252010724\n",
      "0.8833780160857909\n",
      "0.8659517426273459\n",
      "5 .............\n",
      "0.8545576407506702\n",
      "0.878686327077748\n",
      "0.8679624664879356\n",
      "0.8840482573726541\n",
      "0.8739946380697051\n",
      "6 .............\n",
      "0.8558981233243967\n",
      "0.8753351206434317\n",
      "0.8706434316353887\n",
      "0.8847184986595175\n",
      "0.8780160857908847\n",
      "7 .............\n",
      "0.8585790884718498\n",
      "0.8753351206434317\n",
      "0.8719839142091153\n",
      "0.8867292225201072\n",
      "0.886058981233244\n",
      "8 .............\n",
      "0.8532171581769437\n",
      "0.8800268096514745\n",
      "0.8666219839142091\n",
      "0.886058981233244\n",
      "0.8827077747989276\n",
      "9 .............\n",
      "0.853887399463807\n",
      "0.8793565683646113\n",
      "0.8726541554959786\n",
      "0.8847184986595175\n",
      "0.8907506702412868\n",
      "10 .............\n",
      "0.8545576407506702\n",
      "0.8880697050938338\n",
      "0.8820375335120644\n",
      "0.8847184986595175\n",
      "0.8847184986595175\n",
      "11 .............\n",
      "0.849195710455764\n",
      "0.8840482573726541\n",
      "0.881367292225201\n",
      "0.8853887399463807\n",
      "0.8880697050938338\n",
      "12 .............\n",
      "0.8378016085790885\n",
      "0.8853887399463807\n",
      "0.8739946380697051\n",
      "0.8853887399463807\n",
      "0.8887399463806971\n",
      "13 .............\n",
      "0.8297587131367292\n",
      "0.886058981233244\n",
      "0.8800268096514745\n",
      "0.886058981233244\n",
      "0.8954423592493298\n",
      "14 .............\n",
      "0.8310991957104558\n",
      "0.8887399463806971\n",
      "0.8880697050938338\n",
      "0.886058981233244\n",
      "0.8853887399463807\n",
      "15 .............\n",
      "0.8284182305630027\n",
      "0.8833780160857909\n",
      "0.8840482573726541\n",
      "0.886058981233244\n",
      "0.8873994638069705\n",
      "1 .............\n",
      "0.055045871559633024\n",
      "0.43902439024390244\n",
      "0.0\n",
      "0.0\n",
      "0.27906976744186046\n",
      "2 .............\n",
      "0.04608294930875576\n",
      "0.4835164835164835\n",
      "0.0\n",
      "0.022727272727272724\n",
      "0.3022508038585209\n",
      "3 .............\n",
      "0.0639269406392694\n",
      "0.47978436657681944\n",
      "0.03791469194312796\n",
      "0.06629834254143646\n",
      "0.3665594855305466\n",
      "4 .............\n",
      "0.1276595744680851\n",
      "0.5203252032520325\n",
      "0.08333333333333333\n",
      "0.04395604395604396\n",
      "0.36305732484076425\n",
      "5 .............\n",
      "0.24913494809688586\n",
      "0.5121293800539083\n",
      "0.13973799126637557\n",
      "0.044198895027624314\n",
      "0.4470588235294118\n",
      "6 .............\n",
      "0.2950819672131148\n",
      "0.5026737967914439\n",
      "0.11872146118721459\n",
      "0.05494505494505494\n",
      "0.47701149425287365\n",
      "7 .............\n",
      "0.3127035830618892\n",
      "0.507936507936508\n",
      "0.21399176954732513\n",
      "0.14213197969543145\n",
      "0.5142857142857142\n",
      "8 .............\n",
      "0.338368580060423\n",
      "0.5226666666666666\n",
      "0.1810699588477366\n",
      "0.1414141414141414\n",
      "0.5098039215686275\n",
      "9 .............\n",
      "0.3910614525139665\n",
      "0.5212765957446808\n",
      "0.2519685039370078\n",
      "0.14\n",
      "0.5509641873278237\n",
      "10 .............\n",
      "0.3988919667590028\n",
      "0.552278820375335\n",
      "0.28455284552845533\n",
      "0.1568627450980392\n",
      "0.5300546448087432\n",
      "11 .............\n",
      "0.3935309973045822\n",
      "0.5311653116531165\n",
      "0.311284046692607\n",
      "0.16585365853658537\n",
      "0.5449591280653951\n",
      "12 .............\n",
      "0.36649214659685864\n",
      "0.5315068493150685\n",
      "0.24193548387096772\n",
      "0.16585365853658537\n",
      "0.5585106382978723\n",
      "13 .............\n",
      "0.3553299492385787\n",
      "0.5277777777777778\n",
      "0.26337448559670784\n",
      "0.17475728155339806\n",
      "0.5783783783783784\n",
      "14 .............\n",
      "0.3793103448275862\n",
      "0.5337078651685393\n",
      "0.41811846689895465\n",
      "0.17475728155339806\n",
      "0.5390835579514824\n",
      "15 .............\n",
      "0.3962264150943396\n",
      "0.5271739130434783\n",
      "0.32156862745098036\n",
      "0.17475728155339806\n",
      "0.5483870967741935\n"
     ]
    }
   ],
   "source": [
    "t = chi2\n",
    "num = 16\n",
    "\n",
    "split_data(X_train, y_train)\n",
    "select = SelectKBest(t, k=num)\n",
    "select.fit_transform(X_train, y_train)\n",
    "\n",
    "cols = []\n",
    "for x in enumerate(select.get_support(indices=True)):\n",
    "    cols.append(X_train.columns[x[1]])\n",
    "\n",
    "ordered = [x for _,x in sorted(zip(select.scores_,cols))]\n",
    "ordered.reverse()\n",
    "\n",
    "f1 = []\n",
    "acc =[]\n",
    "for x in range(1,num):\n",
    "    f1.append([])\n",
    "    acc.append([])\n",
    "    use = ordered[0:x]\n",
    "    X_train_new = X_train[use].copy()\n",
    "    index = 0\n",
    "    \n",
    "    split_data(X_train_new, y_train)\n",
    "    for i in enumerate(classifiers):\n",
    "        model_results(i[1], s = best_fold[index], d=False, i=(x-1))\n",
    "        index = index+1\n",
    "\n",
    "for x in range(len(acc)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(acc[x])):\n",
    "        print(acc[x][y])\n",
    "for x in range(len(f1)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(f1[x])):\n",
    "        print(f1[x][y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .............\n",
      "0.8599195710455764\n",
      "0.8706434316353887\n",
      "0.8652815013404825\n",
      "0.8833780160857909\n",
      "0.8418230563002681\n",
      "2 .............\n",
      "0.8599195710455764\n",
      "0.8780160857908847\n",
      "0.8659517426273459\n",
      "0.8833780160857909\n",
      "0.8505361930294906\n",
      "3 .............\n",
      "0.863941018766756\n",
      "0.8746648793565683\n",
      "0.8693029490616622\n",
      "0.8833780160857909\n",
      "0.8505361930294906\n",
      "4 .............\n",
      "0.8565683646112601\n",
      "0.8753351206434317\n",
      "0.8699731903485255\n",
      "0.8833780160857909\n",
      "0.8679624664879356\n",
      "5 .............\n",
      "0.8552278820375335\n",
      "0.881367292225201\n",
      "0.8753351206434317\n",
      "0.8833780160857909\n",
      "0.8693029490616622\n",
      "6 .............\n",
      "0.8498659517426274\n",
      "0.8833780160857909\n",
      "0.8800268096514745\n",
      "0.8833780160857909\n",
      "0.8726541554959786\n",
      "7 .............\n",
      "0.8532171581769437\n",
      "0.8773458445040214\n",
      "0.8800268096514745\n",
      "0.8847184986595175\n",
      "0.886058981233244\n",
      "8 .............\n",
      "0.8512064343163539\n",
      "0.8760053619302949\n",
      "0.8806970509383378\n",
      "0.8840482573726541\n",
      "0.8887399463806971\n",
      "9 .............\n",
      "0.846514745308311\n",
      "0.8833780160857909\n",
      "0.8793565683646113\n",
      "0.886058981233244\n",
      "0.8907506702412868\n",
      "10 .............\n",
      "0.853887399463807\n",
      "0.8780160857908847\n",
      "0.8806970509383378\n",
      "0.886058981233244\n",
      "0.8967828418230563\n",
      "11 .............\n",
      "0.8478552278820375\n",
      "0.8806970509383378\n",
      "0.8840482573726541\n",
      "0.8867292225201072\n",
      "0.8967828418230563\n",
      "12 .............\n",
      "0.8505361930294906\n",
      "0.8800268096514745\n",
      "0.8806970509383378\n",
      "0.886058981233244\n",
      "0.8967828418230563\n",
      "13 .............\n",
      "0.846514745308311\n",
      "0.8827077747989276\n",
      "0.886058981233244\n",
      "0.886058981233244\n",
      "0.903485254691689\n",
      "14 .............\n",
      "0.8471849865951743\n",
      "0.886058981233244\n",
      "0.8847184986595175\n",
      "0.8880697050938338\n",
      "0.9041554959785523\n",
      "15 .............\n",
      "0.8532171581769437\n",
      "0.8827077747989276\n",
      "0.8853887399463807\n",
      "0.8880697050938338\n",
      "0.9054959785522788\n",
      "1 .............\n",
      "0.0\n",
      "0.24313725490196078\n",
      "0.0\n",
      "0.0\n",
      "0.21333333333333332\n",
      "2 .............\n",
      "0.0\n",
      "0.4916201117318436\n",
      "0.0099009900990099\n",
      "0.0\n",
      "0.24406779661016947\n",
      "3 .............\n",
      "0.12121212121212122\n",
      "0.49865951742627346\n",
      "0.10958904109589042\n",
      "0.0\n",
      "0.2875399361022364\n",
      "4 .............\n",
      "0.17692307692307693\n",
      "0.5026737967914439\n",
      "0.1339285714285714\n",
      "0.0\n",
      "0.3498349834983499\n",
      "5 .............\n",
      "0.2116788321167883\n",
      "0.5123966942148761\n",
      "0.1982758620689655\n",
      "0.0\n",
      "0.4036697247706422\n",
      "6 .............\n",
      "0.22222222222222224\n",
      "0.5372340425531915\n",
      "0.26337448559670784\n",
      "0.0\n",
      "0.4444444444444444\n",
      "7 .............\n",
      "0.2772277227722772\n",
      "0.5196850393700788\n",
      "0.28685258964143423\n",
      "0.07526881720430106\n",
      "0.5170454545454546\n",
      "8 .............\n",
      "0.31901840490797545\n",
      "0.5144356955380579\n",
      "0.2992125984251969\n",
      "0.08465608465608465\n",
      "0.5202312138728323\n",
      "9 .............\n",
      "0.3284457478005865\n",
      "0.532258064516129\n",
      "0.3023255813953488\n",
      "0.10526315789473682\n",
      "0.5408450704225352\n",
      "10 .............\n",
      "0.384180790960452\n",
      "0.5284974093264249\n",
      "0.31007751937984496\n",
      "0.12371134020618556\n",
      "0.5722222222222222\n",
      "11 .............\n",
      "0.3881401617250674\n",
      "0.5136612021857925\n",
      "0.3422053231939164\n",
      "0.13333333333333336\n",
      "0.5599999999999999\n",
      "12 .............\n",
      "0.3956639566395664\n",
      "0.5122615803814714\n",
      "0.28800000000000003\n",
      "0.1414141414141414\n",
      "0.5698324022346368\n",
      "13 .............\n",
      "0.402088772845953\n",
      "0.5205479452054795\n",
      "0.3609022556390977\n",
      "0.1414141414141414\n",
      "0.5955056179775281\n",
      "14 .............\n",
      "0.40625000000000006\n",
      "0.5502645502645503\n",
      "0.35338345864661647\n",
      "0.17733990147783252\n",
      "0.6060606060606061\n",
      "15 .............\n",
      "0.43989769820971864\n",
      "0.5257452574525745\n",
      "0.3448275862068966\n",
      "0.17733990147783252\n",
      "0.6136986301369863\n"
     ]
    }
   ],
   "source": [
    "t = chi2\n",
    "num = 16\n",
    "\n",
    "split_data(X_train_2, y_train)\n",
    "select = SelectKBest(t, k=num)\n",
    "select.fit_transform(X_train_2, y_train)\n",
    "\n",
    "cols = []\n",
    "for x in enumerate(select.get_support(indices=True)):\n",
    "    cols.append(X_train_2.columns[x[1]])\n",
    "\n",
    "ordered = [x for _,x in sorted(zip(select.scores_,cols))]\n",
    "ordered.reverse()\n",
    "\n",
    "f1 = []\n",
    "acc =[]\n",
    "for x in range(1,num):\n",
    "    f1.append([])\n",
    "    acc.append([])\n",
    "    use = ordered[0:x]\n",
    "    X_train_new = X_train_2[use].copy()\n",
    "    index = 0\n",
    "    \n",
    "    if x ==15:\n",
    "        selected_model_2 = X_train_new.copy()\n",
    "        \n",
    "    split_data(X_train_new, y_train)\n",
    "    for i in enumerate(classifiers):\n",
    "        model_results(i[1], s = best_fold[index], d=False, i=(x-1))\n",
    "        index = index+1\n",
    "        \n",
    "for x in range(len(acc)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(acc[x])):\n",
    "        print(acc[x][y])\n",
    "for x in range(len(f1)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(f1[x])):\n",
    "        print(f1[x][y])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Mutual information gain</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mi = mutual_info_classif(X_train, y_train) \n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False, inplace = True)\n",
    "\n",
    "plt.title('Mutual information with respect to features')\n",
    "mi.plot.bar(figsize = (16,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 41\n",
      "f1 score: [0.39737991266375544, 0.5661375661375662, 0.4172661870503597, 0.16748768472906403, 0.6455026455026455]\n"
     ]
    }
   ],
   "source": [
    "#Drop one of high correlated pair\n",
    "#Multicollinearity\n",
    "pos_data = X_train.corr().abs()\n",
    "unstack_data = pos_data.unstack()\n",
    "corr_data = pd.DataFrame(unstack_data)\n",
    "\n",
    "corrs = []\n",
    "for x in range(62**2):\n",
    "    corrs.append([corr_data.index[x],corr_data.values[x][0]])\n",
    "    \n",
    "corrs = sorted(corrs, key=lambda x: -x[1])\n",
    "corrs = corrs[62:-1: 2]\n",
    "\n",
    "drop_features = []\n",
    "for x in range(len(corrs)):\n",
    "    if corrs[x][1] >= 0.8:\n",
    "        a = corrs[x][0][0]\n",
    "        b = corrs[x][0][1]\n",
    "        if a not in drop_features or b not in drop_features:\n",
    "            if mi[a] >= mi[b]:\n",
    "                c = 1\n",
    "            else:\n",
    "                c = 0\n",
    "            drop_features.append(corrs[x][0][c])\n",
    "        \n",
    "drop_features = list(dict.fromkeys(drop_features))\n",
    "X_train_2 = X_train.drop(columns=drop_features)\n",
    "print(\"Features:\",X_train_2.shape[1])\n",
    "\n",
    "split_data(X_train_2, y_train)\n",
    "\n",
    "f1 = [[]]\n",
    "index = 0\n",
    "for i in enumerate(classifiers):\n",
    "    model_results(i[1], s = best_fold[index], d=False)\n",
    "    index = index+1\n",
    "\n",
    "print(\"f1 score:\",f1[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .............\n",
      "0.8599195710455764\n",
      "0.8760053619302949\n",
      "0.8652815013404825\n",
      "0.8833780160857909\n",
      "0.853887399463807\n",
      "2 .............\n",
      "0.8592493297587132\n",
      "0.8746648793565683\n",
      "0.8646112600536193\n",
      "0.8833780160857909\n",
      "0.8626005361930295\n",
      "3 .............\n",
      "0.8592493297587132\n",
      "0.8706434316353887\n",
      "0.8672922252010724\n",
      "0.8833780160857909\n",
      "0.8626005361930295\n",
      "4 .............\n",
      "0.8605898123324397\n",
      "0.8739946380697051\n",
      "0.8666219839142091\n",
      "0.8833780160857909\n",
      "0.8719839142091153\n",
      "5 .............\n",
      "0.8599195710455764\n",
      "0.8766756032171582\n",
      "0.8666219839142091\n",
      "0.8833780160857909\n",
      "0.878686327077748\n",
      "6 .............\n",
      "0.8579088471849866\n",
      "0.8760053619302949\n",
      "0.8733243967828418\n",
      "0.881367292225201\n",
      "0.8941018766756033\n",
      "7 .............\n",
      "0.8585790884718498\n",
      "0.8800268096514745\n",
      "0.8719839142091153\n",
      "0.881367292225201\n",
      "0.8873994638069705\n",
      "8 .............\n",
      "0.8505361930294906\n",
      "0.8793565683646113\n",
      "0.8753351206434317\n",
      "0.8820375335120644\n",
      "0.8914209115281502\n",
      "9 .............\n",
      "0.8485254691689008\n",
      "0.8800268096514745\n",
      "0.8753351206434317\n",
      "0.881367292225201\n",
      "0.8934316353887399\n",
      "10 .............\n",
      "0.8505361930294906\n",
      "0.8773458445040214\n",
      "0.8746648793565683\n",
      "0.8820375335120644\n",
      "0.8914209115281502\n",
      "11 .............\n",
      "0.8498659517426274\n",
      "0.8827077747989276\n",
      "0.8760053619302949\n",
      "0.8867292225201072\n",
      "0.8887399463806971\n",
      "12 .............\n",
      "0.849195710455764\n",
      "0.878686327077748\n",
      "0.8760053619302949\n",
      "0.8853887399463807\n",
      "0.8867292225201072\n",
      "13 .............\n",
      "0.8445040214477212\n",
      "0.8773458445040214\n",
      "0.8820375335120644\n",
      "0.8853887399463807\n",
      "0.8941018766756033\n",
      "14 .............\n",
      "0.8371313672922251\n",
      "0.8840482573726541\n",
      "0.8806970509383378\n",
      "0.8853887399463807\n",
      "0.8934316353887399\n",
      "15 .............\n",
      "0.8364611260053619\n",
      "0.8847184986595175\n",
      "0.8847184986595175\n",
      "0.886058981233244\n",
      "0.8927613941018767\n",
      "1 .............\n",
      "0.0\n",
      "0.43425076452599387\n",
      "0.0\n",
      "0.0\n",
      "0.2733333333333333\n",
      "2 .............\n",
      "0.07894736842105263\n",
      "0.4848484848484848\n",
      "0.019417475728155338\n",
      "0.0\n",
      "0.3278688524590164\n",
      "3 .............\n",
      "0.07894736842105263\n",
      "0.47978436657681944\n",
      "0.029411764705882353\n",
      "0.0\n",
      "0.30976430976430974\n",
      "4 .............\n",
      "0.11864406779661017\n",
      "0.4946236559139785\n",
      "0.0995475113122172\n",
      "0.0\n",
      "0.3974763406940063\n",
      "5 .............\n",
      "0.11814345991561181\n",
      "0.5053763440860215\n",
      "0.0995475113122172\n",
      "0.011363636363636362\n",
      "0.4498480243161094\n",
      "6 .............\n",
      "0.152\n",
      "0.5066666666666668\n",
      "0.2092050209205021\n",
      "0.0\n",
      "0.5212121212121212\n",
      "7 .............\n",
      "0.1593625498007968\n",
      "0.5175202156334232\n",
      "0.200836820083682\n",
      "0.0\n",
      "0.5087719298245613\n",
      "8 .............\n",
      "0.26885245901639343\n",
      "0.5212765957446808\n",
      "0.23140495867768596\n",
      "0.0\n",
      "0.5149700598802395\n",
      "9 .............\n",
      "0.30246913580246915\n",
      "0.5251989389920425\n",
      "0.256\n",
      "0.0\n",
      "0.5391304347826088\n",
      "10 .............\n",
      "0.35362318840579715\n",
      "0.5271317829457365\n",
      "0.21757322175732216\n",
      "0.011235955056179775\n",
      "0.5549450549450549\n",
      "11 .............\n",
      "0.36\n",
      "0.5283018867924528\n",
      "0.23868312757201648\n",
      "0.0962566844919786\n",
      "0.5337078651685393\n",
      "12 .............\n",
      "0.39024390243902446\n",
      "0.5298701298701298\n",
      "0.23868312757201648\n",
      "0.10471204188481674\n",
      "0.5266106442577031\n",
      "13 .............\n",
      "0.38947368421052636\n",
      "0.5067385444743935\n",
      "0.3333333333333333\n",
      "0.10471204188481674\n",
      "0.5485714285714286\n",
      "14 .............\n",
      "0.38167938931297707\n",
      "0.5361930294906166\n",
      "0.32061068702290074\n",
      "0.10471204188481674\n",
      "0.5571030640668524\n",
      "15 .............\n",
      "0.3869346733668342\n",
      "0.5401069518716577\n",
      "0.3484848484848485\n",
      "0.11458333333333336\n",
      "0.5480225988700564\n"
     ]
    }
   ],
   "source": [
    "t = mutual_info_classif\n",
    "num = 16\n",
    "\n",
    "split_data(X_train, y_train)\n",
    "select = SelectKBest(t, k=num)\n",
    "select.fit_transform(X_train, y_train)\n",
    "\n",
    "cols = []\n",
    "for x in enumerate(select.get_support(indices=True)):\n",
    "    cols.append(X_train.columns[x[1]])\n",
    "\n",
    "ordered = [x for _,x in sorted(zip(select.scores_,cols))]\n",
    "ordered.reverse()\n",
    "\n",
    "f1 = []\n",
    "acc =[]\n",
    "for x in range(1,num):\n",
    "    f1.append([])\n",
    "    acc.append([])\n",
    "    use = ordered[0:x]\n",
    "    X_train_new = X_train[use].copy()\n",
    "    \n",
    "    if num == 15:\n",
    "        selected_data = X_train_new.copy()\n",
    "    index = 0\n",
    "    \n",
    "    split_data(X_train_new, y_train)\n",
    "    for i in enumerate(classifiers):\n",
    "        model_results(i[1], s = best_fold[index], d=False, i=(x-1))\n",
    "        index = index+1\n",
    "\n",
    "for x in range(len(acc)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(acc[x])):\n",
    "        print(acc[x][y])\n",
    "for x in range(len(f1)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(f1[x])):\n",
    "        print(f1[x][y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .............\n",
      "0.8599195710455764\n",
      "0.8760053619302949\n",
      "0.8652815013404825\n",
      "0.8833780160857909\n",
      "0.8558981233243967\n",
      "2 .............\n",
      "0.8599195710455764\n",
      "0.871313672922252\n",
      "0.8652815013404825\n",
      "0.8833780160857909\n",
      "0.8605898123324397\n",
      "3 .............\n",
      "0.8599195710455764\n",
      "0.8793565683646113\n",
      "0.8706434316353887\n",
      "0.8833780160857909\n",
      "0.853887399463807\n",
      "4 .............\n",
      "0.8599195710455764\n",
      "0.8806970509383378\n",
      "0.8693029490616622\n",
      "0.8833780160857909\n",
      "0.8659517426273459\n",
      "5 .............\n",
      "0.8565683646112601\n",
      "0.8739946380697051\n",
      "0.8693029490616622\n",
      "0.8833780160857909\n",
      "0.8719839142091153\n",
      "6 .............\n",
      "0.8585790884718498\n",
      "0.8766756032171582\n",
      "0.8739946380697051\n",
      "0.8853887399463807\n",
      "0.8853887399463807\n",
      "7 .............\n",
      "0.8619302949061662\n",
      "0.878686327077748\n",
      "0.8780160857908847\n",
      "0.8853887399463807\n",
      "0.8840482573726541\n",
      "8 .............\n",
      "0.8605898123324397\n",
      "0.8766756032171582\n",
      "0.8739946380697051\n",
      "0.8847184986595175\n",
      "0.8887399463806971\n",
      "9 .............\n",
      "0.8451742627345844\n",
      "0.8780160857908847\n",
      "0.8760053619302949\n",
      "0.8840482573726541\n",
      "0.8900804289544236\n",
      "10 .............\n",
      "0.8438337801608579\n",
      "0.8780160857908847\n",
      "0.8833780160857909\n",
      "0.8827077747989276\n",
      "0.8880697050938338\n",
      "11 .............\n",
      "0.8398123324396782\n",
      "0.8766756032171582\n",
      "0.8827077747989276\n",
      "0.8840482573726541\n",
      "0.8914209115281502\n",
      "12 .............\n",
      "0.8357908847184986\n",
      "0.8746648793565683\n",
      "0.8853887399463807\n",
      "0.8847184986595175\n",
      "0.8974530831099196\n",
      "13 .............\n",
      "0.8264075067024129\n",
      "0.8806970509383378\n",
      "0.8894101876675603\n",
      "0.8853887399463807\n",
      "0.896112600536193\n",
      "14 .............\n",
      "0.8250670241286864\n",
      "0.8800268096514745\n",
      "0.881367292225201\n",
      "0.8853887399463807\n",
      "0.9014745308310992\n",
      "15 .............\n",
      "0.8297587131367292\n",
      "0.881367292225201\n",
      "0.8780160857908847\n",
      "0.886058981233244\n",
      "0.8941018766756033\n",
      "1 .............\n",
      "0.0\n",
      "0.4051446945337621\n",
      "0.0\n",
      "0.0\n",
      "0.2711864406779661\n",
      "2 .............\n",
      "0.0\n",
      "0.4866310160427808\n",
      "0.0\n",
      "0.0\n",
      "0.2925170068027211\n",
      "3 .............\n",
      "0.07929515418502203\n",
      "0.5081967213114754\n",
      "0.09389671361502348\n",
      "0.0\n",
      "0.29677419354838713\n",
      "4 .............\n",
      "0.07929515418502203\n",
      "0.5291005291005292\n",
      "0.08450704225352113\n",
      "0.0\n",
      "0.3333333333333333\n",
      "5 .............\n",
      "0.07758620689655174\n",
      "0.4891304347826087\n",
      "0.0930232558139535\n",
      "0.0\n",
      "0.3737704918032787\n",
      "6 .............\n",
      "0.26989619377162627\n",
      "0.5106382978723405\n",
      "0.19658119658119658\n",
      "0.03389830508474576\n",
      "0.4672897196261682\n",
      "7 .............\n",
      "0.3223684210526316\n",
      "0.519893899204244\n",
      "0.20869565217391306\n",
      "0.03389830508474576\n",
      "0.4741641337386018\n",
      "8 .............\n",
      "0.3246753246753247\n",
      "0.5157894736842106\n",
      "0.16814159292035397\n",
      "0.033707865168539325\n",
      "0.5\n",
      "9 .............\n",
      "0.3225806451612903\n",
      "0.5159574468085105\n",
      "0.19913419913419914\n",
      "0.022598870056497175\n",
      "0.514792899408284\n",
      "10 .............\n",
      "0.3545706371191135\n",
      "0.5309278350515464\n",
      "0.3149606299212599\n",
      "0.05405405405405405\n",
      "0.5044510385756676\n",
      "11 .............\n",
      "0.3523035230352304\n",
      "0.5183246073298429\n",
      "0.2971887550200803\n",
      "0.08465608465608465\n",
      "0.5149700598802395\n",
      "12 .............\n",
      "0.3501326259946949\n",
      "0.5091863517060368\n",
      "0.30204081632653057\n",
      "0.08510638297872342\n",
      "0.5486725663716815\n",
      "13 .............\n",
      "0.3375959079283887\n",
      "0.5291005291005292\n",
      "0.4329896907216495\n",
      "0.09523809523809525\n",
      "0.5427728613569321\n",
      "14 .............\n",
      "0.3425692695214106\n",
      "0.5226666666666666\n",
      "0.33207547169811324\n",
      "0.09523809523809525\n",
      "0.5714285714285715\n",
      "15 .............\n",
      "0.36180904522613067\n",
      "0.528\n",
      "0.272\n",
      "0.10526315789473682\n",
      "0.5511363636363638\n"
     ]
    }
   ],
   "source": [
    "t = mutual_info_classif\n",
    "num = 16\n",
    "\n",
    "split_data(X_train_2, y_train)\n",
    "select = SelectKBest(t, k=num)\n",
    "select.fit_transform(X_train_2, y_train)\n",
    "\n",
    "cols = []\n",
    "for x in enumerate(select.get_support(indices=True)):\n",
    "    cols.append(X_train_2.columns[x[1]])\n",
    "\n",
    "ordered = [x for _,x in sorted(zip(select.scores_,cols))]\n",
    "ordered.reverse()\n",
    "\n",
    "f1 = []\n",
    "acc =[]\n",
    "for x in range(1,num):\n",
    "    f1.append([])\n",
    "    acc.append([])\n",
    "    use = ordered[0:x]\n",
    "    X_train_new = X_train_2[use].copy()\n",
    "    index = 0\n",
    "        \n",
    "    if x ==15:\n",
    "        selected_model_3 = X_train_new.copy()\n",
    "    \n",
    "    split_data(X_train_new, y_train)\n",
    "    for i in enumerate(classifiers):\n",
    "        model_results(i[1], s = best_fold[index], d=False, i=(x-1))\n",
    "        index = index+1\n",
    "        \n",
    "for x in range(len(acc)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(acc[x])):\n",
    "        print(acc[x][y])\n",
    "for x in range(len(f1)):\n",
    "    print(x+1,\".............\")\n",
    "    for y in range(len(f1[x])):\n",
    "        print(f1[x][y])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Selected features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>BLOSUM4</th>\n",
       "      <th>KF3</th>\n",
       "      <th>BLOSUM7</th>\n",
       "      <th>VHSE4</th>\n",
       "      <th>ProtFP7</th>\n",
       "      <th>BLOSUM1</th>\n",
       "      <th>Z3</th>\n",
       "      <th>VHSE8</th>\n",
       "      <th>ST7</th>\n",
       "      <th>T4</th>\n",
       "      <th>F4</th>\n",
       "      <th>T2</th>\n",
       "      <th>BLOSUM3</th>\n",
       "      <th>BLOSUM10</th>\n",
       "      <th>KF1</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>Epitope</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LDRLFNKKKELGQDK</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.319087</td>\n",
       "      <td>0.319924</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.649659</td>\n",
       "      <td>0.538047</td>\n",
       "      <td>0.649828</td>\n",
       "      <td>0.244074</td>\n",
       "      <td>0.238011</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.524941</td>\n",
       "      <td>0.641526</td>\n",
       "      <td>0.858511</td>\n",
       "      <td>0.224756</td>\n",
       "      <td>0.242321</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LKLDRLFNKKKELGQ</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.280445</td>\n",
       "      <td>0.370778</td>\n",
       "      <td>0.503704</td>\n",
       "      <td>0.626224</td>\n",
       "      <td>0.533291</td>\n",
       "      <td>0.571542</td>\n",
       "      <td>0.184021</td>\n",
       "      <td>0.208228</td>\n",
       "      <td>0.458730</td>\n",
       "      <td>0.597038</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.850613</td>\n",
       "      <td>0.175896</td>\n",
       "      <td>0.260068</td>\n",
       "      <td>0.365729</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NKYKLKLDRLFNKKK</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.351874</td>\n",
       "      <td>0.455408</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.656482</td>\n",
       "      <td>0.649017</td>\n",
       "      <td>0.588469</td>\n",
       "      <td>0.169447</td>\n",
       "      <td>0.240788</td>\n",
       "      <td>0.427671</td>\n",
       "      <td>0.507404</td>\n",
       "      <td>0.609287</td>\n",
       "      <td>0.888590</td>\n",
       "      <td>0.113192</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.460642</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RLFNKKKELGQDKMQ</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.227166</td>\n",
       "      <td>0.375712</td>\n",
       "      <td>0.475926</td>\n",
       "      <td>0.678434</td>\n",
       "      <td>0.440393</td>\n",
       "      <td>0.649564</td>\n",
       "      <td>0.219315</td>\n",
       "      <td>0.212014</td>\n",
       "      <td>0.516383</td>\n",
       "      <td>0.532736</td>\n",
       "      <td>0.543831</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>0.172638</td>\n",
       "      <td>0.333106</td>\n",
       "      <td>0.371696</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YKLKLDRLFNKKKEL</th>\n",
       "      <th>E-10004</th>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.398482</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.599229</td>\n",
       "      <td>0.594800</td>\n",
       "      <td>0.520233</td>\n",
       "      <td>0.166813</td>\n",
       "      <td>0.242554</td>\n",
       "      <td>0.398844</td>\n",
       "      <td>0.533905</td>\n",
       "      <td>0.678086</td>\n",
       "      <td>0.873467</td>\n",
       "      <td>0.084691</td>\n",
       "      <td>0.122867</td>\n",
       "      <td>0.367150</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DGNNEDNEKLRKPKH</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.531616</td>\n",
       "      <td>0.233397</td>\n",
       "      <td>0.445370</td>\n",
       "      <td>0.732127</td>\n",
       "      <td>0.545656</td>\n",
       "      <td>0.869611</td>\n",
       "      <td>0.418262</td>\n",
       "      <td>0.347804</td>\n",
       "      <td>0.539234</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>0.459323</td>\n",
       "      <td>0.767938</td>\n",
       "      <td>0.328583</td>\n",
       "      <td>0.393857</td>\n",
       "      <td>0.570332</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDKRDGNNEDNEKLR</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.513466</td>\n",
       "      <td>0.227325</td>\n",
       "      <td>0.274537</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>0.598605</td>\n",
       "      <td>0.903994</td>\n",
       "      <td>0.395610</td>\n",
       "      <td>0.273852</td>\n",
       "      <td>0.501937</td>\n",
       "      <td>0.351520</td>\n",
       "      <td>0.488092</td>\n",
       "      <td>0.918669</td>\n",
       "      <td>0.328990</td>\n",
       "      <td>0.370648</td>\n",
       "      <td>0.514635</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDNEKLRKPKHKKLK</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.220141</td>\n",
       "      <td>0.275901</td>\n",
       "      <td>0.501389</td>\n",
       "      <td>0.671314</td>\n",
       "      <td>0.484147</td>\n",
       "      <td>0.779423</td>\n",
       "      <td>0.184197</td>\n",
       "      <td>0.402070</td>\n",
       "      <td>0.651192</td>\n",
       "      <td>0.444271</td>\n",
       "      <td>0.542696</td>\n",
       "      <td>0.876155</td>\n",
       "      <td>0.115635</td>\n",
       "      <td>0.240273</td>\n",
       "      <td>0.389031</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KRDGNNEDNEKLRKP</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.405152</td>\n",
       "      <td>0.296015</td>\n",
       "      <td>0.445370</td>\n",
       "      <td>0.764165</td>\n",
       "      <td>0.604312</td>\n",
       "      <td>0.877281</td>\n",
       "      <td>0.352239</td>\n",
       "      <td>0.352347</td>\n",
       "      <td>0.542386</td>\n",
       "      <td>0.391660</td>\n",
       "      <td>0.493360</td>\n",
       "      <td>0.855318</td>\n",
       "      <td>0.326140</td>\n",
       "      <td>0.290785</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNEDNEKLRKPKHKK</th>\n",
       "      <th>E-43575</th>\n",
       "      <td>0.398127</td>\n",
       "      <td>0.284630</td>\n",
       "      <td>0.483796</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>0.544388</td>\n",
       "      <td>0.866438</td>\n",
       "      <td>0.290606</td>\n",
       "      <td>0.374054</td>\n",
       "      <td>0.613369</td>\n",
       "      <td>0.354638</td>\n",
       "      <td>0.447084</td>\n",
       "      <td>0.903200</td>\n",
       "      <td>0.179967</td>\n",
       "      <td>0.280546</td>\n",
       "      <td>0.493038</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14919 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          BLOSUM4       KF3   BLOSUM7     VHSE4   ProtFP7   BLOSUM1        Z3     VHSE8       ST7        T4        F4        T2   BLOSUM3  BLOSUM10       KF1     Class\n",
       "ID              Epitope                                                                                                                                                                \n",
       "LDRLFNKKKELGQDK E-10004  0.319087  0.319924  0.423611  0.649659  0.538047  0.649828  0.244074  0.238011  0.457679  0.524941  0.641526  0.858511  0.224756  0.242321  0.411765  Negative\n",
       "LKLDRLFNKKKELGQ E-10004  0.280445  0.370778  0.503704  0.626224  0.533291  0.571542  0.184021  0.208228  0.458730  0.597038  0.707107  0.850613  0.175896  0.260068  0.365729  Negative\n",
       "NKYKLKLDRLFNKKK E-10004  0.351874  0.455408  0.538889  0.656482  0.649017  0.588469  0.169447  0.240788  0.427671  0.507404  0.609287  0.888590  0.113192  0.036177  0.460642  Negative\n",
       "RLFNKKKELGQDKMQ E-10004  0.227166  0.375712  0.475926  0.678434  0.440393  0.649564  0.219315  0.212014  0.516383  0.532736  0.543831  0.886574  0.172638  0.333106  0.371696  Negative\n",
       "YKLKLDRLFNKKKEL E-10004  0.311475  0.398482  0.488889  0.599229  0.594800  0.520233  0.166813  0.242554  0.398844  0.533905  0.678086  0.873467  0.084691  0.122867  0.367150  Negative\n",
       "...                           ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...\n",
       "DGNNEDNEKLRKPKH E-43575  0.531616  0.233397  0.445370  0.732127  0.545656  0.869611  0.418262  0.347804  0.539234  0.336321  0.459323  0.767938  0.328583  0.393857  0.570332  Positive\n",
       "EDKRDGNNEDNEKLR E-43575  0.513466  0.227325  0.274537  0.749333  0.598605  0.903994  0.395610  0.273852  0.501937  0.351520  0.488092  0.918669  0.328990  0.370648  0.514635  Positive\n",
       "EDNEKLRKPKHKKLK E-43575  0.220141  0.275901  0.501389  0.671314  0.484147  0.779423  0.184197  0.402070  0.651192  0.444271  0.542696  0.876155  0.115635  0.240273  0.389031  Positive\n",
       "KRDGNNEDNEKLRKP E-43575  0.405152  0.296015  0.445370  0.764165  0.604312  0.877281  0.352239  0.352347  0.542386  0.391660  0.493360  0.855318  0.326140  0.290785  0.588235  Positive\n",
       "NNEDNEKLRKPKHKK E-43575  0.398127  0.284630  0.483796  0.712251  0.544388  0.866438  0.290606  0.374054  0.613369  0.354638  0.447084  0.903200  0.179967  0.280546  0.493038  Positive\n",
       "\n",
       "[14919 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"BLOSUM4\", \"KF3\", \"BLOSUM7\", \"VHSE4\", \"ProtFP7\", \"BLOSUM1\", \"Z3\", \"VHSE8\", \"ST7\", \"T4\", \"F4\", \"T2\", \"BLOSUM3\", \"BLOSUM10\", \"KF1\",\"Class\"]\n",
    "features = data[cols].copy()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_pickle(\"Features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
